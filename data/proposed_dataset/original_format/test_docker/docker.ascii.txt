[2016-11-21 13:06:23] <sirroland> Hello. Help solve the problem please.Dockerfile: [<-CODE->] When I run a container returns an error: [<-CODE->] (but /root/run.sh File exists)
[2016-11-21 13:09:37] <sirroland> in Dockerfile all right, I'm wrong here\nNow I will try, thank you
[2016-11-21 13:10:30] <sirroland>  [<-CODE->]
[2016-11-21 13:11:23] <krzysztof-magosa> you can try also with /bin/sh
[2016-11-21 13:12:26] <sirroland> krzysztof-magosa:  [<-CODE->]
[2016-11-21 13:12:52] <sirroland> Docker version 1.12.3, build 6b644ec
[2016-11-21 13:14:05] <krzysztof-magosa> try
[2016-11-21 13:14:15] <krzysztof-magosa> CMD [ "/bin/sh", "/root/run.sh"]
[2016-11-21 13:15:51] <sirroland> CMD [ "/bin/sh", "/root/run.sh"] it\'s work. thanks
[2016-11-21 13:16:10] <krzysztof-magosa> ;-)
[2016-11-21 14:49:22] <sirroland> How I can start nginx and php on starting container?
[2016-11-21 14:49:44] <sirroland>  [<-CODE->] not working ((
[2016-11-21 14:58:00] <gudron> Hi guys.
[2016-11-21 14:59:21] <gudron> i have stupd question;i have two physical server with docker engine on board.1 - with mysql container2 - with apps containers
[2016-11-21 15:00:52] <gudron> I need to create a network between the two docker-host
[2016-11-21 15:01:27] <gudron> what should I do? what tool to use?
[2016-11-21 15:02:54] <vkrot> gudron: , have you checked this [<-LINK->] ?
[2016-11-21 15:05:33] <gudron> hm...
[2016-11-21 15:05:58] <gudron> i must do it on every host?
[2016-11-21 18:34:59] <killerspaz> krzysztof-magosa: @sirrolandif you want/bin/shto be your interpreter just supply CMD as a quoted array as you have; see: [<-LINK->] 
[2016-11-21 18:38:18] <dragon788> sirroland: you'll probably need to put those two commands in a single  .sh file and execute it via cmd
[2016-11-21 18:56:59] <marcfielding1> @sirroland I think you simply need && after the first start so [<-CODE->] CMD executes a single command so by using && you get it to do both - at least thats my understanding
[2016-11-22 13:20:39] <LuizTibo> Hi guys, I need a docker compose to  use with php 7, postgresql, mongo e nodejs. Do you have some example?
[2016-11-22 13:40:58] <marcelmfs> LuizTibo: : [<-LINK->] 
[2016-11-22 17:25:54] <Speechkey_twitter> Hi folks, [<-CODE->]  [<-CODE->] On that way the logs should be written: [<-CODE->]
[2016-11-22 18:28:31] <aaronmcadam> hey everyone, are there any good patterns for copying production credential files to an image? We were thinking of putting our credential files on S3 and downloading them
[2016-11-22 19:10:00] <Speechkey_twitter> aaronmcadam:  [<-LINK->] 
[2016-11-22 19:10:00] <Speechkey_twitter> aaronmcadam:  [<-LINK->] 
[2016-11-22 19:20:15] <aaronmcadam> Thanks@Speechkey_twitter, does that support using files?
[2016-11-23 08:44:20] <ShurikAg> hi all
[2016-11-23 08:44:20] <ShurikAg> hi all
[2016-11-23 08:44:51] <ShurikAg> Is there a way to set folder ownership on mounted volume?
[2016-11-23 08:44:51] <ShurikAg> Is there a way to set folder ownership on mounted volume?
[2016-11-23 08:45:30] <ShurikAg> Somehow, when I change permissions once, it’s kept on my local docker but not on AWS.
[2016-11-23 08:45:30] <ShurikAg> Somehow, when I change permissions once, it’s kept on my local docker but not on AWS.
[2016-11-23 18:08:05] <lucasjahn> ShurikAg: I have a really similar file permission issue. So upvote for any helpful tipp on this :)
[2016-11-23 18:17:45] <dragon788> I'd suggest checking this out, since running as root is definitely an anti-pattern that should be avoided, [<-LINK->] 
[2016-11-23 23:24:22] <zapcode> can i use docker in a virtualbox ?
[2016-11-23 23:24:35] <MadMub> yes
[2016-11-23 23:24:43] <MadMub> just be careful with docker and vagrant
[2016-11-23 23:24:57] <MadMub> docker inside a vm through vagrant gets effed
[2016-11-23 23:25:11] <zapcode> some link about this ?
[2016-11-23 23:25:25] <MadMub> about vagrant?
[2016-11-23 23:25:29] <MadMub> Or docker in a vm?
[2016-11-23 23:25:46] <zapcode> about docker run in vbox
[2016-11-23 23:25:55] <MadMub> just install and use normally
[2016-11-23 23:26:06] <MadMub> docker can basically inside anything with a linux kernel
[2016-11-23 23:26:27] <MadMub> docker on windows used to be docker through a linux vm
[2016-11-23 23:26:48] <MadMub> docker on amazon ecs is docker running on a vm
[2016-11-23 23:27:12] <zapcode> yes, i install in my windows but the problem is activate hyper and break the virtualbox
[2016-11-23 23:27:17] <MadMub> haha
[2016-11-23 23:27:18] <MadMub> yes
[2016-11-23 23:27:27] <MadMub> a host operating system can only have 1 hypervisor
[2016-11-23 23:27:36] <zapcode> i write a command that i can select in the booting if activate/desactivate hyper
[2016-11-23 23:27:47] <zapcode> but the docker not run if i need vbox
[2016-11-23 23:27:56] <zapcode> and vbox no run if i select hyper and no like this
[2016-11-23 23:28:14] <zapcode> i need can use the two without reboot
[2016-11-23 23:28:16] <MadMub> on windows, you cannot run both hyper and vbox
[2016-11-23 23:28:22] <MadMub> on any os
[2016-11-23 23:28:30] <MadMub> you cant run competing hypervisors
[2016-11-23 23:28:36] <MadMub> to me knowledge at least
[2016-11-23 23:29:13] <MadMub> if you have hyperv just use that it can do everything vbox does
[2016-11-25 12:30:52] <scippio> hi all I\'m trying start nginx via:docker run --network "host" -e NGINX_PORT=8080 2f3c6710d8f2but I get only:2016/11/25 12:29:06 [emerg] 1#1: bind() to 0.0.0.0:80 failed (98: Address in use)\nnginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address in use)
[2016-11-25 12:31:14] <scippio> How I can change the port in [<-LINK->] image ...? :/
[2016-11-25 12:49:56] <lucasjahn> you should use the --expose option for this
[2016-11-25 12:50:33] <lucasjahn>  [<-CODE->] 
[2016-11-25 12:51:38] <lucasjahn> have a look at the commandline  reference here [<-LINK->] or directly in the nginx image docs [<-LINK->] in the section exposing ports, there you have a direct example
[2016-11-25 12:52:04] <lucasjahn>  [<-CODE->] this would map your local port 8080 to the port 80 in the container
[2016-11-25 13:25:10] <scippio> lucasjahn: still have same problem
[2016-11-25 13:25:23] <scippio> withdocker run --network "host" -p 8080:80 -e NGINX_PORT=8080 2f3c6710d8f2
[2016-11-25 13:47:14] <lucasjahn> you set NGINX_PORT=8080
[2016-11-25 13:47:18] <lucasjahn> so you should adjust
[2016-11-25 13:47:25] <lucasjahn> -p 8080:8080
[2016-11-25 13:47:28] <lucasjahn> to this
[2016-11-25 13:47:50] <lucasjahn> can you just paste in your error again in here?
[2016-11-25 14:01:19] <scippio> docker run --network "host" -p 8080:8080 -e NGINX_PORT=8080 2f3c6710d8f2
[2016-11-25 14:01:22] <scippio> still same error
[2016-11-25 14:01:34] <scippio>  [<-CODE->] 
[2016-11-25 14:02:01] <scippio> it's ignore my 8080 settings :/
[2016-11-25 14:11:41] <matrixbot> uhoregAre you sure the image you\'re using supports NGINX_PORT?  Don\'t use \'--network "host"\'.  Just do "docker run -p 8080:80 nginx"
[2016-11-25 14:16:31] <scippio> but I want --network "host"
[2016-11-25 14:17:11] <scippio> I'm using this image: [<-LINK->] 
[2016-11-25 14:17:47] <scippio> hmm...
[2016-11-25 14:17:47] <scippio> "Out-of-the-box, Nginx doesn\'t support using environment variables inside most configuration blocks. But envsubst..."
[2016-11-25 15:02:10] <lucasjahn> and what happens if you just run it like@matrixbotsaid?
[2016-11-25 15:02:16] <lucasjahn> still the error?
[2016-11-25 15:35:01] <scippio> lucasjahn: no.. it\'s ok. but I need --network "host" option ... so I must build my own image from nginx:alpine ...
[2016-11-25 17:14:52] <Benjman> Sorry if this is the wrong channel, but can anyone tell me where I might see the log output for an AWS ECS container I'm trying to start a docker container on? I think it's failing, but I have no idea where to see if it is.
[2016-11-26 11:55:53] <ilgooz> is it possible to auto pull volumes from registry while doing docker service create? do i have to manually ssh into all swarm nodes and do a pull of my volume(container) each time a new version is ready?
[2016-11-27 15:44:51] <ImFlog> Hello, I have an issue with swarm. I have a simple java application which tries to call another application. I use swarm for my deployment through a network overlay. The problem is that when I scale an app, I can validate that the hosts behind the VIP are updated but my client keeps calling the same addresses.I tried a lot of things like changing java DNS cache ttlAnyone ever had something like that ?
[2016-11-28 02:43:03] <gadget_mnky_twitter> Hi, looking to scale my existing compose file across multiple hosts using swarm. Any examples I could follow?
[2016-11-28 16:06:12] <mikewrighton> hi! does anyone happen to know about inspecting execution state in a container? when youexeca command you can see the exec id in the container state, and the docker API allows you to query that state (e.g. to see whether it’s running) but I don’t see any docs for command line support
[2016-11-28 16:06:45] <mikewrighton> in other words, my question is can you do this in the CLI tool: [<-LINK->]
[2016-11-28 17:15:04] <Forecaster> mikewrighton: you mean this? [<-LINK->]
[2016-11-28 17:16:32] <mikewrighton> so I can rundocker inspectto get the list of current exec ids for a container, but I can’t seem to actually inspect the execution state for those exec ids
[2016-11-28 17:18:18] <mikewrighton> I tried runningdocker inspect<exec id> but gotError: No such image, container or task:<exec id>
[2016-11-28 17:19:03] <mikewrighton> unless I’m missing something, it seems like this is not implemented for the CLI tool?
[2016-11-28 17:20:37] <Forecaster> maybe if you request the data as json from the container?
[2016-11-28 17:23:20] <mikewrighton> oh, how can I try that?
[2016-11-28 17:29:04] <Forecaster> oh, the default format is json it appears
[2016-11-28 17:29:44] <Forecaster> if that doesn't contain it then you may be stuck with the api
[2016-11-28 17:35:40] <mikewrighton> yeah it looks like it, thanks anyway.
[2016-11-28 21:25:01] <mikewrighton> I getError: No such image, container or task: a9952be2c74f2c6f3a7ae9faf12dc1576367bba5197fe74c243b637289fb653b
[2016-11-28 21:25:16] <mikewrighton> but an exec id is not an image, container or task
[2016-11-28 21:26:05] <mikewrighton> so docker inspect, as far as I can tell, does not support quering exec ids
[2016-11-28 22:53:10] <dragon788> mikewrighton: I think you are correct, inspect is mostly for containers and images
[2016-11-29 20:32:40] <dearfrankg> has anyone had problems with nginx-proxy?
[2016-11-30 15:11:51] <jdevillard> Hello, I'm new on docker, I would like to know if there is some UI and/or orchestrator that allow me to manage multiple cluster in one place. I understand that there is many Docker UI available but it seems that it allows to manage only one cluster (or maybe I miss something). Indeed my cluster will be hosted on Azure, in different Vnet and I would like a single interface to manage them all. Do you have any idea?
[2016-11-30 15:24:18] <marcelmfs> check rancher.com
[2016-11-30 15:25:30] <jdevillard> interesting thanks@marcelmfs!
[2016-12-01 18:59:41] <rightisleft> Im trying to replace my brew docker instance with a dockerized version - i can start the container - and see my data from within the container - but when i try and access it on the exposed port on os x - i get connection refused
[2016-12-01 18:59:46] <rightisleft> docker run -d --net po-net -p 5432:5432 -e POSTGRES_USER='rightisleft' -e POSTGRES_DB='mydb' --env 'PG_TRUST_LOCALNET=true' -v /usr/local/var/postgres:/var/lib/postgresql/data --name po-postgres postgres:9.5
[2016-12-01 19:00:38] <rightisleft> database psql -U rightisleft -d mydbpsql: could not connect to server: Connection refusedIs the server running locally and acceptingconnections on Unix domain socket "/tmp/.s.PGSQL.5432"?
[2016-12-01 19:01:13] <rightisleft> docker ps -a show it active with the following ports - 0.0.0.0:5432->5432/tcp
[2016-12-03 21:08:25] <renegoretzka> heyo =) does anyone use docker with caddy (as webserver)?
[2016-12-05 10:18:10] <christhomas> hey guys, so I am wondering how you all manage your docker compose definitions, say I have an api, built in a microservice architecture, it results in something like 50+ docker compose services and I am wondering, if there is a better way to setup all these services using tools instead of hardcoded yml files on disk
[2016-12-05 10:19:56] <christhomas> I guess a nicer way would be through some interface, where I can build the configurations and house them in a tool which I could run, store them in a backend database, then I could manage them easier, any tools which you guys run that would help? or do you run everything using docker run? I guess not, cause multi service architectures would be a bit tricky to manage
[2016-12-05 11:37:57] <Forecaster> I use Rancher
[2016-12-05 11:46:24] <christhomas> ok, thats a good answer, thanks
[2016-12-05 18:57:12] <renegoretzka> i host all the websites
[2016-12-05 18:58:45] <renegoretzka>  [<-CODE->] 
[2016-12-05 18:58:54] <renegoretzka> i think this will just run very good
[2016-12-05 18:59:56] <renegoretzka> i can add a volume to my wordpress to load my wordpress files from my host volume where i save all my stuff.. how to do the volume to it?
[2016-12-05 19:05:15] <renegoretzka> dragon788: you know what i mean?
[2016-12-05 19:14:25] <dragon788>  [<-CODE->]  [<-CODE->] iirc
[2016-12-06 09:15:40] <ely029> I created a docker-compose.yml filehere is the code `frontend:  image: ubuntu:14.04web:  build: .  command: apt-get update  command: apt-get install php7.0  command: apt-get install apache2  command: apt-get install subversion  volumes: [<-CODE->] ports: [<-CODE->] links: [<-CODE->]  [<-CODE->] Is there something wrong in my yml file?
[2016-12-06 20:09:10] <RahulConqueror> Please guide me how to start on learning basics of Docker DevOps
[2016-12-07 04:43:17] <siassaj> ave
[2016-12-07 04:44:31] <siassaj> I am curious, when I want to deploy an image that I've built locally is it possible (or even plausible) to upload only that top application layer that's changed, and let my machines fetch the lower layers from cache?
[2016-12-07 07:00:24] <siassaj> Lakshman-LD: ok, that makes sense. So i think maybe I need a server on the same network/data centre as my app servers that will pull from github, build the image then deploy (meaning only the shared layers get sent to the app servers)
[2016-12-07 07:00:38] <siassaj> so probably time to go figure out how to do that, thank you :)
[2016-12-07 07:09:50] <lakshmantgld> :)
[2016-12-07 04:43:17] <siassaj> ave
[2016-12-07 04:44:31] <siassaj> I am curious, when I want to deploy an image that I've built locally is it possible (or even plausible) to upload only that top application layer that's changed, and let my machines fetch the lower layers from cache?
[2016-12-07 05:05:01] <lakshmantgld> siassaj: I think trhe layers are introduced for reducing the payload during the uploads. So, the layers are automatically recognized and only those layers that are changed, will be sent as payload.
[2016-12-07 07:00:24] <siassaj> Lakshman-LD: ok, that makes sense. So i think maybe I need a server on the same network/data centre as my app servers that will pull from github, build the image then deploy (meaning only the shared layers get sent to the app servers)
[2016-12-07 07:00:38] <siassaj> so probably time to go figure out how to do that, thank you :)
[2016-12-07 07:09:50] <lakshmantgld> :)
[2016-12-07 13:24:32] <dragon788> siassaj: there is a docker container for the registry that is free to use
[2016-12-07 15:38:21] <desprit> I have docker-compose file with about 7 services in it. How should I organize tests? Make a separate service for testing  to test all my containers or do tests inside each container?
[2016-12-07 16:16:33] <scippio> Hi all ... I starting my container via docker-compose with this command:/bin/bash -c "envsubst \'$$NGINX_UPSTREAM\' < /etc/nginx/nginx.conf.template > /etc/nginx/nginx.conf && nginx -g \'daemon off;\'"
[2016-12-07 16:17:05] <scippio> all is fine... but docker kill -s HUP <containerID> does not work :(
[2016-12-07 16:49:20] <scippio> docker exec <containerID> nginx -s reloadworks fine ... 
[2016-12-07 17:10:33] <marcelmfs> scippio: most probably because you're not using a signal forwarding process manager likehttps://github.com/krallin/tini
[2016-12-07 17:11:27] <marcelmfs> huangyanxiong01: you needcontainer_name: nodeandhostname: nodein order for docker to correctly associate to the container name and hostname.
[2016-12-07 17:24:20] <agustinvinao> OSX question: Im using native docker and when i go to the console my docker-machine is not active, is that a normal thing? I need to do eval $(docker-machine env default) to make it available
[2016-12-07 17:33:10] <scippio> marcelmfs: ok... thanks.. I'll try tini..
[2016-12-07 18:47:39] <scippio> marcelmfs: is this right? [<-CODE->] 
[2016-12-07 19:20:33] <Trezamere> If I've got a docker container running docker (teamcity agent running builds) what is the best way to mount a volume in the 'parent' container into the 'child' container?
[2016-12-07 19:22:25] <Trezamere> The 'parent' container has the host docker socket bound (-v /var/run/docker.sock:) so when the agent (parent container) tries to run a new container and pass some -v flags; the -v flags don't get mounted correctly as far as I can tell
[2016-12-07 19:27:55] <Trezamere> presumably because it's not actually a child; but a sibling; and the directory trying to be mounted doesn't actually exist outside the 'parent'
[2016-12-08 09:41:11] <marcelmfs> scippio: I'm not sure. In order for tini to work as expected, it needs to be your entrypoint, and be assigned PID 1.
[2016-12-08 09:41:49] <marcelmfs> only then tini will forward signals to it's child processes
[2016-12-08 10:33:52] <scippio> marcelmfs: I had resolved the issue ... I created a bash scrip with all my commands + nginx exec at the end and tini as entrypoint ... and all is fine now :)
[2016-12-07 20:54:49] <sbbowers__twitter> Hello, is it possible to mount the mysql socket file directly into a docker container?
[2016-12-07 20:58:09] <sbbowers__twitter> Or basically any method that would allow me to connect to a vanilla mysql server running on the host.
[2016-12-08 19:55:16] <renegoretzka> heyo.. i get error 502 bad gateway using fpm and caddyserver
[2016-12-08 19:55:34] <renegoretzka> but i dont get why
[2016-12-08 20:06:44] <renegoretzka> Can anybody help me with this issue?
[2016-12-08 23:24:47] <sbbowers__twitter> that message means that caddyserver can't talk to your fpm server.
[2016-12-09 10:58:01] <tsm91> hi
[2016-12-09 11:01:02] <tsm91> i would like to dockerize a project that consist of:a frontend codebase (angular 2, after npm run build all the STATIC files i need is in the dist directory)\na backend codebase (a nodejs app w/o any transpilation build process)the production nginx.conf file looks like this: [<-CODE->] the backend api got a dependency for mongodb, so i will need a node, mongo, nginx Dockerfile
[2016-12-09 11:01:39] <tsm91> what i am not sure is,  to which image's filesystem should i put the frontend static files? It should be in the nginx image. Am i correct?
[2016-12-09 11:02:50] <am0nshi> if it 100% static its better to put them into ngixn, but you can mount physical directory into both images, its depends on how you will build your containers
[2016-12-09 11:46:29] <kschlesselmann> If they're only needed in the frontend I'd put them there, yes. After you all you don't ship a nginx but your frontend.
[2016-12-09 18:45:00] <drew-r> god damn it is there a single CI platform that does docker properly
[2016-12-09 18:45:34] <dragon788> drew-r: docker properly in what way?
[2016-12-09 22:50:40] <drew-r> dragon788: docker 1.10 at least and supports compose and doesn't do weird shit like codefresh
[2016-12-09 22:51:44] <dragon788> tried AWS or looked at Linode and managing your own version of Docker?
[2016-12-09 23:26:12] <FuzzOli87> Hello all! Maybe you guys can help me out, been beating this up all day.
[2016-12-09 23:26:55] <FuzzOli87> I'm trying to create a base docker image that would allow me to use volumes and have them be created with the same permission as the host. This is the base image for our containers:
[2016-12-09 23:27:02] <FuzzOli87>  [<-LINK->]
[2016-12-09 23:27:55] <FuzzOli87> This is the Dockerfile for using it in an application:
[2016-12-09 23:27:56] <FuzzOli87>  [<-LINK->]
[2016-12-09 23:28:46] <dragon788> FuzzOli87: you can see if this gives you any more clarity [<-LINK->]
[2016-12-10 21:28:56] <Forecaster> Hm, I'm having an odd issue
[2016-12-10 21:28:56] <Forecaster> Hm, I'm having an odd issue
[2016-12-10 21:29:09] <Forecaster> I'm trying to set up a php <-> nginx environment
[2016-12-10 21:29:09] <Forecaster> I'm trying to set up a php <-> nginx environment
[2016-12-10 21:29:29] <Forecaster> I have them in separate containers, with a link from the nginx container to the php one called "php"
[2016-12-10 21:29:29] <Forecaster> I have them in separate containers, with a link from the nginx container to the php one called "php"
[2016-12-10 21:30:10] <Forecaster> in the nginx config I have a fastcgi_pass to "php:9000", which fails with a bad gateway "connection refused"
[2016-12-10 21:30:10] <Forecaster> in the nginx config I have a fastcgi_pass to "php:9000", which fails with a bad gateway "connection refused"
[2016-12-10 21:30:40] <Forecaster> if I ping "php" from inside the nginx container it tells me it\'s pinging the ip 103.224.182.212
[2016-12-10 21:30:40] <Forecaster> if I ping "php" from inside the nginx container it tells me it\'s pinging the ip 103.224.182.212
[2016-12-10 21:30:52] <Forecaster> but the ip of the php container is 10.42.187.89
[2016-12-10 21:30:52] <Forecaster> but the ip of the php container is 10.42.187.89
[2016-12-10 21:31:09] <Forecaster> if I replace "php" with 10.42.187.89 in the nginx config for the cgi_pass it works
[2016-12-10 21:31:09] <Forecaster> if I replace "php" with 10.42.187.89 in the nginx config for the cgi_pass it works
[2016-12-10 21:31:20] <Forecaster> why is the link pointing to the wrong ip? D:
[2016-12-10 21:31:20] <Forecaster> why is the link pointing to the wrong ip? D:
[2016-12-10 21:37:31] <Forecaster> it's not the host ip
[2016-12-10 21:37:31] <Forecaster> it's not the host ip
[2016-12-10 23:11:28] <GastroGeek> @Forecaster - are you doing the linking at runtime via docker run --link ? might be worth posting your full command and any Dockerfile/docker-composer.yml etc.I just ran docker-composer up on this: [<-CODE->] and it links through OK (assuming you set up the nginx/php confs OK) - but the php:9000 part appears to be working. [<-CODE->] 
[2016-12-10 23:11:28] <GastroGeek> @Forecaster - are you doing the linking at runtime via docker run --link ? might be worth posting your full command and any Dockerfile/docker-composer.yml etc.I just ran docker-composer up on this: [<-CODE->] and it links through OK (assuming you set up the nginx/php confs OK) - but the php:9000 part appears to be working. [<-CODE->]
[2016-12-10 23:12:23] <GastroGeek> @Forecaster - also, I think --link is deprecated?https://docs.docker.com/engine/userguide/networking/default_network/dockerlinks/
[2016-12-10 23:12:23] <GastroGeek> @Forecaster - also, I think --link is deprecated?https://docs.docker.com/engine/userguide/networking/default_network/dockerlinks/
[2016-12-10 23:43:38] <Forecaster> Hm
[2016-12-10 23:43:44] <Forecaster> well, the link is created by Rancher
[2016-12-10 23:43:51] <Forecaster> I believe it uses -links
[2016-12-10 23:44:51] <Forecaster>  [<-CODE->]
[2016-12-10 23:45:16] <Forecaster> that's the docker-compose it generates
[2016-12-10 23:48:21] <Forecaster> is that the same as run --link?
[2016-12-10 23:51:42] <Forecaster> GastroGeek:
[2016-12-10 23:52:52] <Forecaster> Rancher uses version 1 of docker-compose though
[2016-12-10 23:52:56] <Forecaster> it can't use version 2
[2016-12-11 00:02:55] <Forecaster> hm, maybe it can, there's been a few new versions...
[2016-12-11 00:03:05] <Forecaster> but how to upgrade it without loosing my settings
[2016-12-11 00:03:13] <Forecaster> I don't know if they're kept inside the container or not
[2016-12-11 00:04:05] <Forecaster> ah there's a process for it in their docs, good
[2016-12-11 00:35:42] <Forecaster> Hm, well, I updated rancher which now supports version 2, which allows networks, and I specified a network in my setup instead of the link
[2016-12-11 00:35:54] <Forecaster> but now when I try to go to the site it says it can't be reached...
[2016-12-11 00:39:36] <Forecaster> does the container need to be on some network to be accessible from the outside even when a port is open?
[2016-12-11 01:04:14] <Forecaster> I can get it working using a link and the container ip
[2016-12-11 01:04:23] <Forecaster> other combinations will not work
[2016-12-11 01:04:35] <Forecaster> : |
[2016-12-11 01:05:08] <Forecaster> time for bed. Continue tinkering tomorrow
[2016-12-11 01:05:16] <Forecaster> I'd really like this to work properly
[2016-12-11 01:06:49] <Forecaster>  [<-CODE->] This works, but if I remove the link it stops working, or if I try to use the link name instead of the ip
[2016-12-11 23:12:24] <jjohnson1994> Hello, I'm trying to install mysql-server in my Dockerfile but the script breaks when the MySQL installer asks to set the root password. Is there a way I can supply a password in the Dockerfile somewhere? I'll put my Dockerfile bellow... [<-CODE->] 
[2016-12-11 23:15:07] <Forecaster> why are you making a mysql image instead of using the official one?
[2016-12-11 23:15:35] <jjohnson1994> I'm not making a MySQL images, plus I just want to learn Docker
[2016-12-11 23:16:05] <Forecaster> you're making an image with mysql in it
[2016-12-11 23:16:11] <Forecaster> :P
[2016-12-11 23:16:30] <rollymaduk> jjohnson1994: have you tried installing quietly using the -q -y switch
[2016-12-11 23:16:56] <rollymaduk> FROM ubuntu:16.04RUN apt-get update && apt-get install -q -y \\git \\nginx \\mysql-server \\php7.0-fpm php-mysql \\php7.0-mysql
[2016-12-11 23:17:02] <Forecaster> the official mysql image gets the root password from an environment variable you supply when you run it in a container
[2016-12-11 23:17:16] <jjohnson1994> rollymaduk: I'll try that now, thanks :)
[2016-12-11 23:17:17] <Forecaster> I don't know how they implement that though
[2016-12-11 23:19:34] <rollymaduk> FYI I agree with@Forecaster.. you really should use the official image and its best practice to have a single container manage a single app/service, you can alway connect them by linking
[2016-12-11 23:20:02] <jjohnson1994> Forecaster: &@rollymadukso would you leave mysql-server out of the Dockerfile and include the image later on in the docker-compose.yml?
[2016-12-11 23:20:45] <jjohnson1994> I'm trying to set up a LEMP environment if it helps
[2016-12-12 08:22:06] <Forecaster> jjohnson1994: I have Nginx, PHP and MySQL all in separate containers
[2016-12-12 08:22:28] <Forecaster> I use pre-made images for each of them
[2016-12-12 08:24:21] <Forecaster> mysql:latestphp:7-fpmnginx:latest
[2016-12-12 09:13:40] <Forecaster> There is also a pre-made but unoffical nginx+fpm image, but that uses php5
[2016-12-12 10:23:16] <jjohnson1994> Thanks@Forecaster, would you mind sharing your docker-compose.yml?
[2016-12-12 10:24:08] <Forecaster>  [<-CODE->] 
[2016-12-12 10:24:41] <Forecaster> There
[2016-12-12 10:28:55] <jjohnson1994> Thanks a lot@Forecaster, I'm missing a lot of that in mine
[2016-12-12 10:48:13] <Forecaster> No problem
[2016-12-15 06:26:56] <mingsterism> i managed to get the container running. but i ended up with this problem. any ideas?
[2016-12-15 06:26:58] <mingsterism>  [<-CODE->]
[2016-12-15 06:27:14] <mingsterism> this is my docker-compose filedockerC1
[2016-12-15 06:27:24] <mingsterism>  [<-CODE->]
[2016-12-15 06:39:17] <mingsterism> im using digitalocean $  20 /mo$0.030 /hour2 GB / 2 CPUs40 GB SSD disk3 TB transfer
[2016-12-15 13:35:48] <smahi> Hi,I am new to docker and i am building lemp stack using docker every thing work as expected beside some permission issues, how to fix permissions so that php can create files/folders ( the right way).Knowing that i am using nginx:alpine, php:fpm-alpine and a custom container volume
[2016-12-15 15:41:03] <dragon788> smahi: read back a little bit, I pasted a link regarding a good practice for changing permissions for an app
[2016-12-15 16:41:14] <smahi> dragon788: thank you for the link.I did not understand your last question :can you justdocker pullthe image that you are building from to see if it is locally?sorry about that.
[2016-12-15 16:57:26] <dragon788> smahi: sorry, was mixing up my conversations, that one was for another convo
[2016-12-15 16:58:05] <dragon788> kind of sad Gitter doesn't have threading like FlowDock, but that's probably the only thing I really miss, as everything else is very GitHub oriented with the pulls/commits/issues
[2016-12-15 17:25:38] <smahi> dragon788: Thank you again for your kindness and help 
[2016-12-16 14:40:09] <siassaj> So I'm trying to figure out a way to build images that arecompletedbuilds for my rails app deployments. I've basically read a bunch of stuff and come to the conclusion that I should create an image that has all my base dependencies like ruby version, nodejs, etc. Then i should create a dockerfile using that image as base, then copying over my 'tmp' directory that contains build cache, my 'node_modules' dir that contains previously downloaded javascript dependencies, and similarly so for my gems, and my javascript and image/css precompiled assets. After copying them into the image i can run my ruby 'build' tasks, then save all the new tmp, node_modules etc contents back to the host computer filesystem, and finish off the dockerfile.
[2016-12-16 14:40:41] <siassaj> If i'm not mistake this can give me very fast build times with minimal downloading etc and leads to a single image that I can spin up on any number of machines very quickly
[2016-12-16 14:40:47] <siassaj> does this approach make any sense?
[2016-12-16 14:42:05] <siassaj> apologies for the lack of sensible terminology.
[2016-12-16 14:45:54] <marcelmfs> if you want to leverage caching of build tasks, yes, that's the best solution. But to release a container for production, I usually remove build tools and ship the container with the minimum to run the service.
[2016-12-16 14:47:06] <siassaj> I dont understand shipping containers
[2016-12-16 14:47:19] <siassaj> i thought you ship images, and when you run them you end up with a container on the host system
[2016-12-16 14:47:54] <siassaj> are you saying i should build everything first, then copy what i need into a docker image?
[2016-12-16 14:47:58] <siassaj> that could work too
[2016-12-16 16:40:50] <siassaj> and a docker image isn't 1 file is it, it's a bunch of slices and some meta data describing which slice in which order, eh?
[2016-12-16 16:19:16] <siassaj> also I don't understand how distributing images works. Ithinkwhat happens is that you 'push' an image to a repo, which is actually sending meta data + a bunch of layersafterchecking the repo to see if it already has those layers or not. As in it only sends up what it needs to
[2016-12-16 16:19:19] <siassaj> is that correct?
[2016-12-16 16:19:41] <siassaj> well the scary part was the hacks I saw to get specific layers not to cache
[2016-12-16 16:19:56] <siassaj> which I undrestand busts everything after
[2016-12-16 17:16:28] <dragon788> siassaj: you are correct, if you are building on top of the same base layer for a specific image "repository" then it will already have that base layer if you have previous pushed an image to it, then it only has to transfer the newer/different layers
[2016-12-16 17:16:52] <dragon788> what tricks for cache busting are you referring to?
[2016-12-16 22:37:10] <hillct> I wonder if someone more knowledgeable than I might be able to speak to this issue: [<-ISSUE->]
[2016-12-17 06:39:20] <siassaj> dragon788: i saw a few, i don't remember exactly off the top of my head.
[2016-12-17 06:43:28] <siassaj> so i need to create an image to serve as my 'base' image for my application images
[2016-12-17 06:44:25] <siassaj> so instead of FROM ruby:2.3.1 I'd rather do FROM my-company-app-env
[2016-12-17 06:45:09] <siassaj> and I suspect that I'll have a bunch of other utility apps with their own docker images, possibly basing off other app enviroments, such as my slackbot etc
[2016-12-17 06:45:20] <siassaj> these 'base' images that I want to use, should each have a director and a Dockefile
[2016-12-17 06:46:15] <siassaj> or should I just create a dir like 'company-dockerfiles',  and put 'app-env.dockerfile', 'slackbot-env.dockerfile', etc
[2016-12-17 06:46:16] <siassaj> ?
[2016-12-17 14:15:28] <xiaopeng163> I am writing a docker k8s lab handbook [<-LINK->]
[2016-12-18 21:53:26] <krishnaghatti_twitter> i am checking out the " --read-only” option ..was wondering how to set that as default in the docker DOCKER_OPTS. Did any one try it out?
[2016-12-18 21:54:35] <krishnaghatti_twitter> i want to start all my docker images RO by default and want to set RO as default option.
[2016-12-18 21:54:57] <krishnaghatti_twitter> some thing like this worksdocker run -t -i -d --read-only --tmpfs /run --tmpfs /tmp python:3 /bin/bash
[2016-12-18 21:55:13] <krishnaghatti_twitter> want to set it as default with DOCKER_OPTS
[2016-12-19 02:45:50] <siassaj> are there any strategies to speed up docker COPY commands. I have to copy several cache directories from host into my image so that my asset compilation and app build is fast. But these directories are full of files.
[2016-12-19 02:46:00] <siassaj> Is it faster to tar them first, transfer the tar and untar it (or use ADD)
[2016-12-19 02:46:20] <siassaj> even ENV commands take several seconds to complete
[2016-12-19 02:48:14] <siassaj> perhaps I'll load host volumes instead of copying
[2016-12-19 02:49:34] <siassaj> ah i see I'd have to mount it, run my commands then commit the container to a new image
[2016-12-19 21:44:36] <mamartins> hello
[2016-12-19 21:44:56] <mamartins> trying to run a container but I get that node modules are missing
[2016-12-19 22:01:27] <dragon788> mamartins: the container may assume you already rannpm installin the directory where the Dockerfile and packages.json is loacated?
[2016-12-19 22:04:12] <mamartins> I run CMD ls node_modules and modules are there!
[2016-12-19 22:04:18] <mamartins> now it is working but I did nothing
[2016-12-19 22:04:50] <mamartins> strange ...
[2016-12-19 22:06:20] <mamartins> found what I add to make it work
[2016-12-19 22:06:21] <mamartins> CMD ls node_modulesCMD npm start
[2016-12-19 22:06:26] <mamartins> the first CMD
[2016-12-19 22:06:36] <mamartins> i'll remove to check it problem returns
[2016-12-19 22:17:41] <mamartins> ok error again
[2016-12-19 22:17:43] <mamartins> error:  TypeError: Cannot read property 'find' of undefinedat Object.module.exports.adapter.find (/app/node_modules/sails-mongo/lib/adapter.js:353:17)at module.exports.find (/app/node_modules/waterline/lib/waterline/adapter/dql.js:120:13)at _runOperation (/app/node_modules/waterline/lib/waterline/query/finders/operations.js:408:29)at run (/app/node_modules/waterline/lib/waterline/query/finders/operations.js:69:8)at module.exports.find (/app/node_modules/waterline/lib/waterline/query/finders/basic.js:264:16)at Deferred.exec (/app/node_modules/waterline/lib/waterline/query/deferred.js:477:16)at module.exports.findOrCreate (/app/node_modules/waterline/lib/waterline/query/composite.js:56:2
[2016-12-19 22:37:09] <dragon788> that sounds like a failure of node inside the container, you might ask in the nodejs/node channel about that
[2016-12-19 22:37:48] <mamartins> indeed
[2016-12-20 15:30:26] <Iamgowtham29_twitter> Gulp watch is not working on docker with volume sharing ,could anyone share some suggestion to make it working
[2016-12-21 07:27:21] <Iamgowtham29_twitter> @galvesribeirothanks for the suggestion I ll look on to that
[2016-12-21 17:31:58] <sbbowers__twitter> So when I run a docker instance, my entrypoint runs some bootstrapping commands to sync dependancies (specifically php'scomposer install).  These dependencies are written to disk owned by root:root. Is there a way to tell docker (specifically docker-compose) to write files as the user I'm running docker as?
[2016-12-21 17:49:55] <sbbowers__twitter> Looks like docker-composer supports auserkey in the yaml file. I'll try it out, but it would be nice if there was an agnostic way to let all developers run the same config.
[2016-12-21 18:09:21] <dragon788> sbbowers__twitter: typically this is construct you create inside your container that picks up the user running the container's ID and chown all the files inside the container to that user during the build
[2016-12-21 18:09:53] <dragon788>  [<-LINK->] 
[2016-12-21 18:38:37] <sbbowers__twitter> dragon788: So the "standard approach" is to bake in "gosu" into all of your docker images by curling a binary off the net and then require your entrypoint to run the command through that, which gives you the option of passing an environment variable with the ID of your current user, all of which won\'t work with docker-compose. Do I understand that right?
[2016-12-21 18:40:30] <dragon788> I thinkgosuis one way to do it, but really since it isn't recommended to run as root anyways, a lot of containers will chmod everything to a known user and run everything as that, the trick is whether that UID exists on your system or not
[2016-12-21 18:47:38] <sbbowers__twitter> So the easy way would to do auseradd -u {some arbitrary ID I pick} docker-useron the host and then pass that user ID to docker's -u?
[2016-12-21 18:48:25] <sbbowers__twitter> If I specify "docker-user" to docker, will it resolve the ID from the host, or does it do a useradd and create a new user?
[2016-12-21 18:52:19] <dragon788>  [<-LINK->] 
[2016-12-21 18:54:27] <dragon788> this appears to have a workaround on an open bug that is somewhat related, [<-ISSUE->] 
[2016-12-21 18:54:27] <dragon788> this appears to have a workaround on an open bug that is somewhat related, [<-ISSUE->] 
[2016-12-21 19:05:50] <dragon788> np@sbbowers__twitterI just make it up as I go along :D
[2016-12-20 07:47:02] <arjunurs> Hi, I am noticing that the container files don’t update after the host files change in a mounted volume. I would appreciate any suggestions
[2016-12-20 21:31:57] <arjunurs> Hi, I have a volume mapped from host to container in docker-compose.yml but the container files don’t seem to update when I change the host file. Any suggestions?
[2016-12-21 00:02:18] <darkSasori> arjunurs: the volume is mapped in Dockerfile?
[2016-12-21 18:05:59] <renegoretzka> hello. i use rancher and using caddyserver as container and cant forward to my wordpress container, i tried to ping the wordpress container and i gives answer, but still cant proxy to my wordpress.. you could help me figure out my problem?
[2016-12-21 19:00:54] <renegoretzka> hmm
[2016-12-21 19:00:58] <renegoretzka> no one can help me out?
[2016-12-21 19:01:53] <dragon788> hi@renegoretzkayou might need to ping the Rancher channel as I'm not that familiar with how that platform interacts with containers and forwarding
[2016-12-21 19:02:29] <dragon788> at first blush I\'d check and make sure the containers are on the same network "segment" and then that you exposed the appropriate ports from the wordpress container
[2016-12-21 19:03:35] <renegoretzka> gitter dont have a rancher channel
[2016-12-21 19:04:14] <renegoretzka> i linked both, wordpress and caddy server.. and i even can ping them.. thats the weird path
[2016-12-21 19:05:38] <dragon788> you can rundocker exec <wordpress id> ping <caddyIP>@renegoretzka?
[2016-12-21 19:05:50] <dragon788> np@sbbowers__twitterI just make it up as I go along :D
[2016-12-21 19:06:19] <renegoretzka> yea@dragon788
[2016-12-21 19:49:53] <dragon788> I don't know if the container could have telnet, but you could try runningtelnet <caddyIP> portinstead of  ping, does that work?
[2016-12-21 19:50:34] <renegoretzka> hmm
[2016-12-21 19:51:52] <renegoretzka> telnet does not exist
[2016-12-21 20:07:34] <renegoretzka> dragon788: it seems like caddyserver does not get any request from outside
[2016-12-21 20:07:43] <renegoretzka> since caddyserver didnt write anything to log
[2016-12-21 20:07:49] <renegoretzka> what can be the reason?
[2016-12-21 20:51:30] <dragon788> if it doesn't have a port exposed or if the service isn't running properly inside that could be an issue
[2016-12-22 02:21:36] <siassaj> Depending on whether I'm running on staging or on production
[2016-12-22 02:21:43] <siassaj> I need to use a different nginx.config file
[2016-12-22 02:21:56] <siassaj> But i have no idea how to do that. anyone know?
[2016-12-22 07:42:35] <arjunurs> darkSasori: the volume is mapped in docker-compose.yml file [<-CODE->]
[2016-12-22 13:03:31] <darkSasori> arjunurs: and in your Dockerfile has the declaration of volume```VOLUME /source
[2016-12-22 20:55:08] <arjunurs> darkSasori: I have this in the Dockerfile [<-CODE->]
[2016-12-22 22:55:58] <darkSasori> arjunurs: you need addVOLUME /sourceto work
[2016-12-23 07:09:07] <renegoretzka> Hello,I got Caddyserver running. The Database is working correctly now and moved the domain to point to my new server. Somehow I get just a clear Website, even when I curl the webseite I get zero response.I have made a look into the Caddyserver logs and WordPress logs and I get the request, but no response. I also installed nginx as a container and served the nginx to Caddy to see if Caddy is proxying correctly. I get the welcome screen from nginx. So this is working fine, but when I again bind the WordPress container to Caddy its just nothing.Do you have a clue what can be the reason to get no response on the client but requests on the server?Thank you!
[2016-12-23 10:42:11] <galvesribeiro> hey guys
[2016-12-23 10:42:23] <galvesribeiro> after latest update docker don't start anymore on windows
[2016-12-23 10:42:25] <galvesribeiro>  [<-CODE->] 
[2016-12-23 10:42:48] <galvesribeiro> when my PC restart and if I open the preferences app and click on restart I got this:
[2016-12-23 10:42:55] <galvesribeiro>  [<-CODE->] 
[2016-12-23 10:43:01] <galvesribeiro> any idea on what that means?
[2016-12-23 13:54:02] <dragon788> Are you running from an administrator prompt?
[2016-12-23 14:33:32] <galvesribeiro> Nop
[2016-12-23 14:33:46] <galvesribeiro> I just rebooted my pc
[2016-12-26 18:19:55] <pfenig> all: trying to find a simple way to tail or access stdout of a linked container running a simple service from another container (running tests) - I'd rather not modify the container running the service i.e. just use stdout - is there a good way to write stdout to a shared volume??
[2016-12-27 01:17:03] <iDVB> I'm new to docker and have been working at getting react-starter-kit up and running for dev and prod using docker-compose. I keep running into issues no matter how I seem to go about it.  Using straight docker I get it running but I can't seem to browse to the server thats running in the container.
[2016-12-27 01:18:45] <iDVB> When I use docker-compose I get an error likesh: babel-node: not foundwhich I think might be happening because for some reason the container is not in the right directory
[2016-12-27 01:19:10] <iDVB> Anyone that might be able to lend a hand would be very appreciated
[2016-12-27 03:17:34] <iDVB> Easier question.... for those looking to use docker for dev workflows that use hot reloading/auto reloading.... is there a best practise for node_modules folder? I mean the node_modules folder needs to be compiled on the container but conversely I need to setup a volume for the src so hot reloading works. Seems odd tonpm iinto a tmp folder in the dockerfile and then get docker-compose to copy that over into the host machine volume. Not to mention that folder being leftover after compose is shut down.
[2016-12-27 20:46:13] <killerspaz> iDVB: simply supplying the volume of the source root folder should do what you want
[2016-12-29 10:51:59] <munish-dhiman> Is it possible to deploy code on docker swarm using a dockerfile added into the code
[2016-12-29 10:52:00] <munish-dhiman> ?
[2016-12-29 14:24:37] <j6k4m8> munish-dhiman: can you clarify what you’re trying to accomplish?
[2016-12-29 14:25:30] <j6k4m8> (btw there’s a docker/swarm chat too :) )
[2016-12-29 16:13:32] <galvesribeiro> can an application running inside a container detect which port was used as public in-p xxxx:YYYYY? i.e I want to detect what is the port outside the container so the APP can listen to it even when using random ports generated by docker
[2016-12-29 16:24:14] <killerspaz> docker inspect <container_id>
[2016-12-29 16:24:25] <killerspaz> that'll give you everything docker knows about the container
[2016-12-29 16:43:36] <galvesribeiro> killerspaz: I mean from inside the container
[2016-12-29 16:44:19] <killerspaz> did you see this? [<-ISSUE->]
[2016-12-29 16:44:20] <galvesribeiro> I mean, after docker spin up the container, my app needs to be aware of its IP and port exposed by docker so it can start listening on that port
[2016-12-29 16:44:42] <j6k4m8> I would pass those as environment variables if you can — should be easier and safer to run on different machines
[2016-12-29 16:44:54] <killerspaz> yeah was going to ask why not supply the port?
[2016-12-29 16:45:57] <galvesribeiro> Because I dont wnat to be supplying ports each I spin a new container
[2016-12-29 16:46:10] <galvesribeiro> I just want to run it and it resolve itself
[2016-12-29 16:46:29] <galvesribeiro> It is pretty common and useful for those mocroservices scenarios
[2016-12-29 16:46:35] <galvesribeiro> Let me see that issue
[2016-12-29 16:58:41] <galvesribeiro> the issue still open, 3 years...
[2016-12-29 16:58:45] <galvesribeiro> anyway
[2016-12-29 16:59:30] <galvesribeiro> killerspaz: the way docker works today as you are stating works pretty well if you are using simple/regular webapps
[2016-12-29 16:59:46] <galvesribeiro> if you have a complex distributed cluster you will end up with this problem
[2016-12-29 17:00:29] <galvesribeiro> ok look at this [<-LINK->]
[2016-12-29 17:01:10] <killerspaz> yeah don't do that
[2016-12-29 17:01:17] <killerspaz> use docker network properly and you won't have this issue
[2016-12-29 17:01:18] <galvesribeiro> the two containers running that has the SiloHost.exe,EXPOSE 2323on its docker file, and they write to a membership table store its port
[2016-12-29 17:01:23] <galvesribeiro> no no
[2016-12-29 17:01:29] <galvesribeiro> listen
[2016-12-29 17:01:36] <galvesribeiro> (read :P )
[2016-12-29 17:02:26] <galvesribeiro> theOrleansClient.exewhich may be a container or not, read from the Membership table storage and know that both silos are running on 2323 so it try to connect to one of them and fail
[2016-12-29 17:02:41] <galvesribeiro> because the port exposed is 3333 and 4444
[2016-12-29 17:02:47] <killerspaz> imo, you shouldn't be spinning up docker containers manually (unless purely testing that single container alone) nor exposing ports manually (again, unless testing)... docker network bridges take care of all that for you.
[2016-12-29 17:03:05] <killerspaz> again, all 50 of my services run on the same port
[2016-12-29 17:03:05] <galvesribeiro> no it doesn't
[2016-12-29 17:03:09] <galvesribeiro> that is the point
[2016-12-29 17:03:20] <galvesribeiro> the client connects to the silos by reading the membership table
[2016-12-29 17:03:24] <killerspaz> in that drawing, you have no context of any network
[2016-12-29 17:03:34] <galvesribeiro> we don't need the context
[2016-12-29 17:03:36] <galvesribeiro> ignore that
[2016-12-29 17:03:41] <killerspaz> no i'm telling you that you DO
[2016-12-29 17:03:54] <killerspaz> in order for the containers to talk to each other without you having to worry about port mapping
[2016-12-29 17:04:24] <killerspaz> unless you're not detailing enough information, this is the basis of docker and microservices, and not out of the norm
[2016-12-29 17:04:42] <galvesribeiro> assume that the containers are reacheable to each other
[2016-12-29 17:05:15] <killerspaz> i have 50 services per cluster, and about 12 clusters across the globe, and don't have any issues with having to track down ports
[2016-12-29 17:05:47] <galvesribeiro> the problem is that the 1. Server app need to know the port and IP it will bind to so it can write it to membership table. 2. the client read this data from that table so it WILL need IP and PORT each silo is running
[2016-12-29 17:05:50] <galvesribeiro> trust me
[2016-12-29 17:05:53] <killerspaz> so when you spin up your deployment, you're manually runningdocker runlines?
[2016-12-29 17:05:55] <galvesribeiro> the application NEED that
[2016-12-29 17:06:02] <killerspaz> no dude, docker has all that built in natively
[2016-12-29 17:06:07] <galvesribeiro> :(
[2016-12-29 17:06:08] <killerspaz> you don't need to know IPs at all
[2016-12-29 17:06:24] <galvesribeiro> you are not understanding :(
[2016-12-29 17:07:04] <killerspaz> so maybe you can elaborate a bit? Because I'm still not seeing the issue other than your understanding of docker/compose
[2016-12-29 17:07:19] <galvesribeiro> ok... let me try again
[2016-12-29 17:07:36] <galvesribeiro> regardless of how docker manage dns resolution and port binding
[2016-12-29 17:08:00] <galvesribeiro> the server application needs to know which IP:PORT it will listen to and write to the membership store tables
[2016-12-29 17:08:02] <galvesribeiro> got it?
[2016-12-29 17:08:04] <galvesribeiro> now
[2016-12-29 17:08:24] <killerspaz> i'm pretty certain I understand what you're trying to do
[2016-12-29 17:08:28] <galvesribeiro> the client which will read from the membership table will need to be able to reach IP:PORT
[2016-12-29 17:08:28] <killerspaz> you're basically building a mesh
[2016-12-29 17:08:34] <killerspaz> an explicit mesh
[2016-12-29 17:08:40] <galvesribeiro> it is a Distributed Hash Table
[2016-12-29 17:08:45] <killerspaz> which i'm telling you is redundant because docker has that native
[2016-12-29 17:08:47] <galvesribeiro> that manages membership of the cluster
[2016-12-29 17:09:02] <galvesribeiro> ok...
[2016-12-29 17:09:03] <galvesribeiro> so
[2016-12-29 17:09:03] <killerspaz> answer this, are you ever runningdocker runoutside of running unit tests?
[2016-12-29 17:09:22] <galvesribeiro> for the local tests I'm using docker run
[2016-12-29 17:09:33] <galvesribeiro> but I plan to learn and use compose to make it production soon
[2016-12-29 17:09:50] <killerspaz> i'd get that going immediately, you'll see it works all that out really quick
[2016-12-29 17:10:05] <galvesribeiro> it wont
[2016-12-29 17:10:45] <galvesribeiro> the cluster althought they are running the same image, when each machin join the cluster it join the DHT which makes it handle specific part of the messages
[2016-12-29 17:11:07] <galvesribeiro> it is not like a web server that you can reach a service or DNS name that will be round robin balanced to any server
[2016-12-29 17:11:32] <galvesribeiro> the client (based on that membership table) will need to connect specifically for a given silo/server to do specific stuff
[2016-12-29 17:11:23] <killerspaz> you supply services, which docker-compose will institute hostnames as the same name, then ports you can just keep constant, and access viaservice_A:1024,service_B:1024,some_mongo_instance:27017(if using default mongo images with default ports)
[2016-12-29 17:11:33] <killerspaz> docker compose IS a dns
[2016-12-29 17:11:41] <killerspaz> ... effectively
[2016-12-29 17:12:22] <galvesribeiro> ok, but institute default port will make 2 conatiners to run in the same host
[2016-12-29 17:12:32] <killerspaz> mm no
[2016-12-29 17:12:37] <killerspaz> that's already bad construction of containers
[2016-12-29 17:12:46] <killerspaz> they should be separate containers
[2016-12-29 17:13:01] <killerspaz> mongo_users, mongo_logs, mongo_whatever
[2016-12-29 17:13:13] <killerspaz> not just "mongo" and all your dbs are in that container
[2016-12-29 17:13:34] <galvesribeiro> :(
[2016-12-29 17:13:39] <galvesribeiro> you still don't undertand  my problem
[2016-12-29 17:13:40] <galvesribeiro>  [<-LINK->]
[2016-12-29 17:13:51] <galvesribeiro> you deal as it was a regular web app
[2016-12-29 17:13:54] <galvesribeiro> but it is not
[2016-12-29 17:14:00] <galvesribeiro> it is really a distributed cluster
[2016-12-29 17:14:15] <galvesribeiro> and I may have multiples clusters running on the same machine
[2016-12-29 17:14:26] <galvesribeiro> and if I specify a given port they will not be able to run
[2016-12-29 17:14:58] <killerspaz> your clusters should be subnetted
[2016-12-29 17:15:10] <killerspaz> and on different hostnames
[2016-12-29 17:15:16] <galvesribeiro> why?
[2016-12-29 17:15:26] <killerspaz> because best practices
[2016-12-29 17:15:31] <killerspaz> for this reason exactly
[2016-12-29 17:15:41] <killerspaz> you avoid port collission
[2016-12-29 17:15:42] <galvesribeiro> I want have multiple a pool of container host machines
[2016-12-29 17:15:52] <galvesribeiro> and just spin containers in them
[2016-12-29 17:15:56] <galvesribeiro> and ask them to just run
[2016-12-29 17:16:01] <galvesribeiro> that is what I do today with VMs
[2016-12-29 17:16:33] <killerspaz> thus, began docker compose
[2016-12-29 17:16:50] <killerspaz> it does all the subnet and iptable routing for you
[2016-12-29 17:17:00] <galvesribeiro> I already have a notion of what compose does and it don't solve my problem
[2016-12-29 17:17:29] <galvesribeiro> because (again) load balancing is not what I'm looking for...
[2016-12-29 17:17:29] <killerspaz> I think you're trying to over complicate it, honestly.... Not sure what Orleans is for exactly, but it's redundant imo.
[2016-12-29 17:17:37] <killerspaz> i'm not talking about load balancing
[2016-12-29 17:17:51] <killerspaz> i'm talking about host and port resolution
[2016-12-29 17:17:55] <galvesribeiro> ok, so tell me one thing...
[2016-12-29 17:18:09] <galvesribeiro> does docker has service discovery?
[2016-12-29 17:18:14] <killerspaz> yes
[2016-12-29 17:18:18] <galvesribeiro> ok, how?
[2016-12-29 17:18:25] <killerspaz> through hostnames via docker-compose
[2016-12-29 17:18:27] <galvesribeiro> service discovery != DNS resolution
[2016-12-29 17:19:01] <killerspaz> it effectively is though; [<-LINK->]
[2016-12-29 17:19:11] <killerspaz> docker cloud uses docker compose to create the mesh
[2016-12-29 17:19:49] <killerspaz> compltely via hostname, which is the same as the service name
[2016-12-29 17:19:50] <galvesribeiro> service discovery is not just hostnames or DNSs... it is service name (maybe it can be the hostname in case of single node service) plus port
[2016-12-29 17:20:07] <galvesribeiro> links only add HOSTNAME to the machines
[2016-12-29 17:20:11] <galvesribeiro> not service discovery
[2016-12-29 17:21:19] <galvesribeiro> ok, let me ask something else
[2016-12-29 17:21:50] <killerspaz> in traditional service discovery you'd absolutely need the port like you're doing, but i'm saying with docker/kubernetes/etc you do not. The SWARM clusters figure all the routing between subnets for you, and you simply access viaremote_hostname:whatever_port_you_run_inside_container
[2016-12-29 17:21:57] <galvesribeiro> is there a way for my client containers to query "hey docker, what are the conainters running the Image XXXX and what are their published port" ?
[2016-12-29 17:22:34] <killerspaz> I don't believe that's a valid use-case with docker
[2016-12-29 17:22:34] <killerspaz> I don't believe that's a valid use-case with docker
[2016-12-29 17:22:41] <killerspaz> except for health monitoring maybe
[2016-12-29 17:22:41] <killerspaz> except for health monitoring maybe
[2016-12-29 17:22:48] <galvesribeiro> ok, then it doesn't have service discovery :D
[2016-12-29 17:22:50] <killerspaz> but even still, IoC would work better
[2016-12-29 17:22:50] <killerspaz> but even still, IoC would work better
[2016-12-29 17:23:57] <killerspaz> i would say in my app "nc servicename:port` and connect and be done... I dont\' care which of the 20 cloned containers it is, the swarm handles that for me routing to an existing container
[2016-12-29 17:23:57] <killerspaz> i would say in my app "nc servicename:port` and connect and be done... I dont\' care which of the 20 cloned containers it is, the swarm handles that for me routing to an existing container
[2016-12-29 17:24:12] <killerspaz> it's service discovery in the sense that you can access services simply, without having to LOOK them up first.
[2016-12-29 17:24:12] <killerspaz> it's service discovery in the sense that you can access services simply, without having to LOOK them up first.
[2016-12-29 17:24:14] <galvesribeiro> the point is, when my server start, it need to say tosomething"hey I\'m listening on port XXXX and my resolvable hostname is YYYY", then the client will query this same "something" for all the available services
[2016-12-29 17:24:42] <galvesribeiro> I dont' care which of the 20 cloned containers it isThat is the problem... We DO care about which container we are connecting to
[2016-12-29 17:24:55] <killerspaz> ok, but why?
[2016-12-29 17:24:55] <killerspaz> ok, but why?
[2016-12-29 17:25:02] <galvesribeiro>  [<-LINK->]
[2016-12-29 17:25:02] <galvesribeiro>  [<-LINK->] 
[2016-12-29 17:25:05] <killerspaz> I can accept that, just need to understand why
[2016-12-29 17:25:05] <killerspaz> I can accept that, just need to understand why
[2016-12-29 17:25:28] <killerspaz> ignoring orleans atm, what is the actual business case for this
[2016-12-29 17:25:28] <galvesribeiro> because of the membership protocol and the DHT which distribute what and where some actions will happen in Orleans
[2016-12-29 17:25:28] <killerspaz> ignoring orleans atm, what is the actual business case for this
[2016-12-29 17:25:44] <killerspaz> simply because you WANT to use Orleans?
[2016-12-29 17:25:44] <killerspaz> simply because you WANT to use Orleans?
[2016-12-29 17:26:35] <galvesribeiro> no, because I USE Orleans and that is proven piece of tech created by multiple PhDs in Distributed Computing and host huge distributed services like Halo game, Skype, and multiple others
[2016-12-29 17:26:36] <killerspaz> I'm just trying to understand why out of 20 cloned containers you need any one specific one
[2016-12-29 17:26:36] <killerspaz> I'm just trying to understand why out of 20 cloned containers you need any one specific one
[2016-12-29 17:26:41] <galvesribeiro> so trust me, they know what they are doing
[2016-12-29 17:26:57] <dragon788> galvesribeiro: I hope you plan on getting your PhD, because most Microsoft tools require that in order to use them
[2016-12-29 17:26:57] <dragon788> galvesribeiro: I hope you plan on getting your PhD, because most Microsoft tools require that in order to use them
[2016-12-29 17:27:11] <killerspaz> Not saying they don't, but there's other ways to accomplish the same thing that I think are easier
[2016-12-29 17:27:27] <galvesribeiro> because 1 of the actors (the processing unit in Orleans) that I'm interested in is inside that give specific container
[2016-12-29 17:27:28] <killerspaz> but i'm not fully understanding your need
[2016-12-29 17:27:29] <dragon788> the problem is microsoft always ignores existing implementations like etcd/consul/etc and invents their own way of doing things, typically ignoring the existing work done and the pitfalls that have been encountered and worked around
[2016-12-29 17:27:29] <dragon788> the problem is microsoft always ignores existing implementations like etcd/consul/etc and invents their own way of doing things, typically ignoring the existing work done and the pitfalls that have been encountered and worked around
[2016-12-29 17:27:52] <galvesribeiro> dragon788: Orleans works perfectly with Consul, Zookeeper and other membership providers
[2016-12-29 17:27:57] <killerspaz> so they aren't 20 cloned containers in your example then, right? they'd actually be unique containers?
[2016-12-29 17:28:19] <killerspaz> conatiner 1 does something completely different than container 2?
[2016-12-29 17:28:21] <galvesribeiro> dragon788: if you read the link I pasted it mention that... so MS don't ignore anything
[2016-12-29 17:28:34] <galvesribeiro> killerspaz: the OS, Frameworks, APP, they are the same, cloned
[2016-12-29 17:28:46] <galvesribeiro> they just process part of the workload individually
[2016-12-29 17:28:56] <killerspaz> so why would one act differently than the other?
[2016-12-29 17:28:56] <galvesribeiro> the Actors are balanced between the cluster
[2016-12-29 17:29:08] <galvesribeiro> they don't act diff then another
[2016-12-29 17:29:14] <killerspaz> so each container can POTENTIALLY do n-actions?
[2016-12-29 17:29:26] <killerspaz> all as first-class citizens?
[2016-12-29 17:29:29] <galvesribeiro> its hard to explain...
[2016-12-29 17:29:35] <killerspaz> lol sounds like it :P
[2016-12-29 17:29:35] <galvesribeiro> do you know the Actor model?
[2016-12-29 17:29:38] <killerspaz> yes
[2016-12-29 17:29:40] <galvesribeiro> ok
[2016-12-29 17:29:48] <galvesribeiro> in Orleans a cluster is a pool of machines
[2016-12-29 17:29:53] <galvesribeiro> that have same code running
[2016-12-29 17:30:15] <galvesribeiro> the 1 actor instance can be activated anywhere in the cluster
[2016-12-29 17:30:33] <galvesribeiro> in this case on any of container being part of the cluster
[2016-12-29 17:30:35] <galvesribeiro> so
[2016-12-29 17:30:43] <galvesribeiro> assuming that I have 2 containers in the cluster
[2016-12-29 17:31:02] <killerspaz> so key phrase i\'m reading is "any of container"
[2016-12-29 17:31:11] <galvesribeiro> one request comes and activate ActorA on containerA and another comes and activate ActorB in containerB
[2016-12-29 17:31:20] <killerspaz> which means you do not need to know which one, just A container that can do what you need
[2016-12-29 17:31:42] <killerspaz> ok, that is load balancing
[2016-12-29 17:31:44] <galvesribeiro> so while the actors are in memory,  when the client needs to talk to the ActorB it MUST connect directly to containerB
[2016-12-29 17:32:02] <killerspaz> sure
[2016-12-29 17:32:03] <galvesribeiro> the actor balancing and placement is an internal behavior of Orleans
[2016-12-29 17:32:15] <galvesribeiro> not a regular web/tcp NLB thing
[2016-12-29 17:32:37] <killerspaz> I can't help you with Orleans, at all... But again, it sounds heavily redundant based on docker technology
[2016-12-29 17:32:41] <galvesribeiro> and the client figure out where that specific activation is based on that membership table and an activation catalog
[2016-12-29 17:32:54] <galvesribeiro> Orleans is ortogonal
[2016-12-29 17:32:57] <galvesribeiro> to any of this
[2016-12-29 17:33:00] <galvesribeiro> like I said
[2016-12-29 17:33:04] <killerspaz> that's the point though
[2016-12-29 17:33:16] <galvesribeiro> I can create a Membership provider that uses Docker infrastructure
[2016-12-29 17:33:38] <galvesribeiro> just like we did for SQL, Zookeeper, Paxus, etcd, Consul and many other service discovery mechanisms
[2016-12-29 17:33:56] <killerspaz> except you can't, because you don't know your ip/port?
[2016-12-29 17:34:08] <galvesribeiro> so, in order to create that membership provider in Orleans, I need to know where I can query for my containers
[2016-12-29 17:34:26] <killerspaz> i dunno, i have tons of jobs that distribute across multiple clusters and sync across th eworld... i've never had to concern myself with discovery when using docker
[2016-12-29 17:34:56] <galvesribeiro> because you use regular balancing stuff... like DNS  :)
[2016-12-29 17:35:10] <killerspaz> i hit a load balancer, it directs to a container i need, done.... but i always access via hostname. if a container needs to be spun up, it spins up, shuts down when done.
[2016-12-29 17:35:13] <galvesribeiro> which is perfect for Web and basic request/response stateless services
[2016-12-29 17:35:22] <galvesribeiro> yeah, because they are stateless
[2016-12-29 17:35:25] <killerspaz> i don't care which of the 1000 physical bare metal boxes it starts on
[2016-12-29 17:35:35] <galvesribeiro> yes! because they are stateless :P
[2016-12-29 17:35:48] <killerspaz> lol now we're about to get into more wars :P
[2016-12-29 17:35:54] <galvesribeiro> heheheheheh
[2016-12-29 17:36:29] <killerspaz> I believe in stateless design; containers are meant to be ephemeral
[2016-12-29 17:36:43] <galvesribeiro> that issue you first posted is precisely why we need that and tons of people replied with +1 3years ago
[2016-12-29 17:36:53] <galvesribeiro> and they do in Orleans
[2016-12-29 17:36:59] <galvesribeiro> if one container is destroyed
[2016-12-29 17:37:01] <galvesribeiro> no problem
[2016-12-29 17:37:20] <galvesribeiro> the state is persisted and if someone ask for that actor again, it is activated on another server
[2016-12-29 17:38:17] <killerspaz> could you possibly netstat and get the port by process?
[2016-12-29 17:38:49] <galvesribeiro> you mean the client netstat the container host?
[2016-12-29 17:39:00] <killerspaz> inside the container itself
[2016-12-29 17:39:06] <killerspaz> to register it to the Membership Table
[2016-12-29 17:39:16] <galvesribeiro> it does it today
[2016-12-29 17:39:23] <galvesribeiro> I mean
[2016-12-29 17:40:46] <galvesribeiro> when starting a Orleans silo, and has a membership provider configured, it will get that port and IP and write to the membership table
[2016-12-29 17:40:53] <galvesribeiro> that is regardless of docker or whatever
[2016-12-29 17:41:00] <galvesribeiro> the problem is not the silo
[2016-12-29 17:41:20] <galvesribeiro> the image will do aEXPOSE xxxxso all containers internally expose the same port
[2016-12-29 17:41:27] <galvesribeiro> that is OK so fa
[2016-12-29 17:41:28] <galvesribeiro> far
[2016-12-29 17:41:42] <killerspaz> you don't need EXPOSE though
[2016-12-29 17:41:45] <killerspaz> with compose
[2016-12-29 17:41:47] <galvesribeiro> humm
[2016-12-29 17:41:51] <galvesribeiro> ok
[2016-12-29 17:41:54] <galvesribeiro> so ignoring expose
[2016-12-29 17:42:07] <galvesribeiro> the app start and write down its port to the membership
[2016-12-29 17:42:30] <galvesribeiro> next step is the client read the membership table, get the IP and PORT of all silos alive
[2016-12-29 17:42:39] <galvesribeiro> and connect to each one of them on that port
[2016-12-29 17:42:59] <killerspaz> so is it possible to run all members on the same port if they were different hosts?
[2016-12-29 17:43:04] <killerspaz> or is it mandatory to be arbitrary?
[2016-12-29 17:43:51] <galvesribeiro> you mean make all them with-p sameexposedport:someinternalporton all the containers assuming only 1 is running on that same host?
[2016-12-29 17:46:13] <killerspaz> here's an example of my docker-compose.yml: [<-LINK->] 
[2016-12-29 17:46:34] <killerspaz> inside the container, the app spins up some service.. in the case of mongo, they all start on port 27017
[2016-12-29 17:46:45] <killerspaz> but i don't define that, mongo does... i COULD with an ENV var, but I don't
[2016-12-29 17:46:59] <killerspaz> however, all my other containers can access mongo_user:27017 without issue
[2016-12-29 17:47:11] <killerspaz> and mongo itself can load balance to it's own cluster/shards/etc
[2016-12-29 17:47:51] <killerspaz> as for the bottom oneapi.user, that's a nginx load balancer with knowledge of all the associative services. it's the ONLY container exposed in this example.
[2016-12-29 17:48:01] <killerspaz> so external services can contact this cluster
[2016-12-29 17:49:03] <killerspaz> but i can just access viawget api.userfrom any container
[2016-12-29 17:49:09] <killerspaz> ANY container
[2016-12-29 17:49:21] <killerspaz> or vice versa,mongo_users
[2016-12-29 17:49:35] <galvesribeiro> yeah, pretty clean 3-tier web architecture
[2016-12-29 17:49:44] <killerspaz> that's just a snippet of the 50+ that are in there
[2016-12-29 17:50:02] <killerspaz> and only 1 cluster type
[2016-12-29 17:50:04] <galvesribeiro> which is very different from what we do
[2016-12-29 17:50:42] <killerspaz> afaiac, that's how docker is meant to be used
[2016-12-29 17:51:02] <galvesribeiro> yeah that is what I meant in the first place :)
[2016-12-29 17:51:17] <galvesribeiro> docker is easy and really good for simple web applications which mostly are 3-tier apps
[2016-12-29 17:51:45] <galvesribeiro> when you have something complex like actor frameworks and DHT scenarios you have this problem
[2016-12-29 17:51:53] <galvesribeiro> it is not just Orleans
[2016-12-29 17:51:54] <galvesribeiro> I mean
[2016-12-29 17:52:03] <galvesribeiro> Erlang, Akka, they all would have the same issue
[2016-12-29 17:52:26] <galvesribeiro> because they all agree on some membership protocol mostly based on DHTs
[2016-12-29 17:53:16] <killerspaz> and i would never use those with a container system, personally
[2016-12-29 17:53:35] <galvesribeiro> that is the point, they are really good fit for containers
[2016-12-29 17:53:43] <killerspaz> most modern message systems use SWIM algorithm to avoid this
[2016-12-29 17:53:50] <galvesribeiro> ???
[2016-12-29 17:54:00] <galvesribeiro> modern, you mean web :)
[2016-12-29 17:54:08] <killerspaz> anything within the last 10 years
[2016-12-29 17:54:25] <killerspaz> look at how netflix does their stuff... i can guarantee it's more complex that yours and mine combined :P
[2016-12-29 17:54:58] <galvesribeiro> netflix is a streaming service which is 90% of their work focused on web apps :D
[2016-12-29 17:55:06] <killerspaz> not even close
[2016-12-29 17:55:16] <galvesribeiro> there is nothing about distributed computing for netflix :D
[2016-12-29 17:55:21] <galvesribeiro> they just, stream stuff
[2016-12-29 17:55:21] <killerspaz> LOL ok
[2016-12-29 17:55:31] <galvesribeiro> I did an interview with them here :)
[2016-12-29 17:55:33] <killerspaz> that's not remotely true
[2016-12-29 17:55:43] <galvesribeiro> not saying that they are crap
[2016-12-29 17:55:44] <galvesribeiro> they are amazing
[2016-12-29 17:55:50] <galvesribeiro> but it is something focused on web
[2016-12-29 17:55:57] <galvesribeiro> not even close to distributed computing or actors
[2016-12-29 17:56:24] <galvesribeiro> they dont have concurrency and other problems that distributed computing propose to handle
[2016-12-29 17:56:25] <galvesribeiro> anyway
[2016-12-29 17:56:30] <galvesribeiro> lets not bloat the chat with it
[2016-12-29 17:56:36] <killerspaz> lol they most certainly do
[2016-12-29 17:56:59] <galvesribeiro> I just need to figure out a way to create a membership provider for docker
[2016-12-29 17:57:06] <galvesribeiro> to give an Idea
[2016-12-29 17:57:14] <galvesribeiro> do you know Service Fabric?
[2016-12-29 17:58:18] <galvesribeiro> they have a internal "Naming Service" which is basically a service discovery service... so Orleans run perfectly in it... we created a provider that register the silos in this service, and the client ask about the service there
[2016-12-29 17:58:20] <killerspaz> i'm familiar, but never used it
[2016-12-29 17:58:41] <galvesribeiro> so the "Membership Table" is just a concept, which can be implemented anywhere as long as we follow the protocol
[2016-12-29 17:58:46] <galvesribeiro> so SF just works
[2016-12-29 17:59:03] <killerspaz> and how do you define the internal names
[2016-12-29 17:59:19] <galvesribeiro> the same way as Consul and Zookeeper which are K/V dictionary repo
[2016-12-29 17:59:22] <galvesribeiro> internal names?
[2016-12-29 17:59:38] <killerspaz> they have a internal "Naming Service" which is basically a service discovery service
[2016-12-29 18:00:03] <killerspaz> so when you want to discover, do you have to use some randomly generated names, or do you provide them
[2016-12-29 18:00:53] <killerspaz> SF is to Azure as Docker Swarm is to Docker
[2016-12-29 18:01:28] <galvesribeiro> I ask them for ALL the silos in naming service, connect to 1 of them first time, get a list of the Actors activation and later on, based on which actor I want to connect, I specifically connect to that server
[2016-12-29 18:01:42] <galvesribeiro> not exactly
[2016-12-29 18:02:08] <galvesribeiro> when you use swarm there is a notion of service
[2016-12-29 18:02:34] <galvesribeiro> which you client try to connect to it, and it forward to any of the thousands of containers listen on diff internal ports
[2016-12-29 18:02:42] <galvesribeiro> this is basically DNS with port forwarding
[2016-12-29 18:03:01] <killerspaz> no, you have each docker daemon join the swarm (aka DHT)
[2016-12-29 18:03:08] <killerspaz> there's no routing, it's explicit
[2016-12-29 18:03:28] <galvesribeiro> yes they join and form a swarm cluster I understand that
[2016-12-29 18:03:42] <killerspaz> which is what you're trying to accomplish with Orleans from my understanding
[2016-12-29 18:03:54] <galvesribeiro> Orleans already do that
[2016-12-29 18:03:55] <galvesribeiro> but
[2016-12-29 18:03:59] <galvesribeiro> like I said
[2016-12-29 18:04:01] <galvesribeiro> it is plugable
[2016-12-29 18:04:29] <galvesribeiro> so if I can query Swarm I can create a provider for it :D
[2016-12-29 18:04:47] <killerspaz> and what would this provider do?
[2016-12-29 18:05:42] <killerspaz> i just can't understand a reason i'd ever want to access a single container explicitly. Sounds entirely cumbersome.
[2016-12-29 18:06:21] <galvesribeiro> if you understand actors there is multiple reasons for that
[2016-12-29 18:06:37] <galvesribeiro> but the location of the actor is transparent for the developer
[2016-12-29 18:06:40] <galvesribeiro> it "Just run"
[2016-12-29 18:06:50] <galvesribeiro> the framework internally needs to understand that
[2016-12-29 18:07:16] <galvesribeiro> at the server/silo side the provider, register all servers in swarm... as far as I understood, docker already register the containers on swarm as part of a service, good, so no change at all at server
[2016-12-29 18:07:52] <galvesribeiro> so in the client, when it start, the provider must query something to get a list of silos in that cluster that are alive
[2016-12-29 18:08:40] <galvesribeiro> and then when it needs to send a message to a specific actor in a specific server you will connect to that specific silo
[2016-12-29 18:09:36] <galvesribeiro> the load balancing of an actor in Orleans is extremely efficient and beat by far NLB algorithms and reverse proxies
[2016-12-29 18:14:27] <galvesribeiro> but@killerspazdo you think if there is a chance to find what I want, docker swarm docs is the write guy to look for it, right?
[2016-12-29 18:15:12] <killerspaz> yes, in conjunction with docker compose
[2016-12-29 18:15:15] <killerspaz> imo
[2016-12-29 18:15:21] <killerspaz> unless anyone else has any other input
[2016-12-29 18:15:32] <galvesribeiro> ok thank you, really appreciate the help
[2016-12-29 18:15:36] <killerspaz> i wouldn't call myself an expert, but I've just never needed to do what you're trying
[2016-12-29 18:15:38] <galvesribeiro> will have a look on both deeper
[2016-12-29 18:15:50] <killerspaz> and i have concurrent systems all over the place
[2016-12-29 18:16:02] <killerspaz> let me rephrase... i haven't had the need since using docker
[2016-12-29 18:16:32] <killerspaz> and i'm using SWIM technologies to simplify the DHT issues you're having
[2016-12-29 18:17:14] <killerspaz>  [<-LINK->] 
[2016-12-29 18:17:41] <galvesribeiro> that is my point, if docker handle somehow service discovery, I would be more than happy to use it and plug it on docker by a provider
[2016-12-29 18:17:47] <galvesribeiro> yeah I know SWIM
[2016-12-29 18:18:02] <galvesribeiro> it is another variation of PAXOS
[2016-12-29 18:18:23] <killerspaz> we're currently using pattern matching for identifying the node we need to discover, but that's all behind the scenes
[2016-12-29 18:19:35] <killerspaz> so i can send a message in json format if i want like:{ actor: 'User', action: 'sync'}and every node that supports thath command is told to sync, and they are queued into rabbitMQ in batches, then another job that was also listening for the same pattern processes the queue
[2016-12-29 18:19:41] <killerspaz> ... for example.
[2016-12-29 18:19:58] <galvesribeiro> yeah but that is just a pub/sub mechanism
[2016-12-29 18:20:32] <killerspaz> mmm not exactly, it MUST exist
[2016-12-29 18:20:49] <killerspaz> the SWIM impl uses the pattern to do service discovery
[2016-12-29 18:21:02] <killerspaz> which services support this
[2016-12-29 18:21:05] <killerspaz> THEN it messages them
[2016-12-29 18:21:11] <killerspaz> it's very similar to akka actually
[2016-12-29 18:21:21] <galvesribeiro> ok
[2016-12-29 18:21:31] <killerspaz> only i don't need elasticsearch
[2016-12-29 18:21:32] <galvesribeiro> its hard to wrap around our heads on actors... I had a hard time first some years ago... then I found Orleans after I leave MSFT
[2016-12-29 18:21:44] <galvesribeiro> Akka and Erlang is so limited
[2016-12-29 18:22:31] <galvesribeiro> you as a developer in Erlang or Akka, need to instantiate an actor and put it on a specific place in the cluster
[2016-12-29 18:22:36] <galvesribeiro> in orleans you don't do that
[2016-12-29 18:23:24] <galvesribeiro> you get a reference without knowing where the actor is running and call a regular method... that method call is shipped internally to the right silo in the cluster and you will receive the response
[2016-12-29 18:23:38] <galvesribeiro> exceptions are propagated across all nodes etc
[2016-12-29 18:23:39] <galvesribeiro> anyway
[2016-12-29 18:24:06] <galvesribeiro> a very modern (and easy) way to make distribute cloud apps
[2016-12-29 18:27:46] <killerspaz> I've been out of the microsoft world for a bit, other than OS.
[2016-12-29 18:27:56] <killerspaz> not by choice, just how things worked out
[2016-12-29 18:31:01] <galvesribeiro> Ic
[2016-12-29 18:31:04] <galvesribeiro>  [<-ISSUE->] 
[2016-12-29 18:31:22] <galvesribeiro> This issue proposes an introspection rest api just as AWS does
[2016-12-29 18:31:36] <galvesribeiro> That would give me the information I need
[2016-12-29 19:17:55] <dragon788> in orleans you don't do thatyou get a reference without knowing where the actor is running and call a regular method... that method call is shipped internally to the right silo in the cluster and you will receive the response
[2016-12-29 19:18:11] <dragon788> this is what is confusing me, why do you need to find/call the actor yourself if your framework handles that?
[2016-12-29 19:20:24] <dragon788> in your example if Client B talks to Container B and initiates a session, you just need to ensure that session persists between B and B, not add the ridiculous complexity of pulling out all this information from the containers and discovering the overall topology of the entire cluster, that way lies madness
[2016-12-29 19:20:48] <dragon788> it sounds like you are defeating the purpose of Orleans if you are doing all this extra work
[2016-12-29 19:36:08] <galvesribeiro> dragon788: there are two roles here
[2016-12-29 19:36:26] <galvesribeiro> I as an application developer which use Orleans dont need to care about it
[2016-12-29 19:37:25] <galvesribeiro> But I as an Orleans maintainer which is trying to make Orleans to run on container needs to know and implement it. Because behind the scenes the framework uses it
[2016-12-29 19:42:25] <dragon788> are you running this in house or on a cloud hosting solution? reading the Orleans whitepaper they recommend using Zookeeper if in house, or Azure Tables/SQL if elsewhere
[2016-12-29 19:47:13] <galvesribeiro> dragon788: it doesnt matter actually. It is just a general suggestion. Zookeeper is just one of many membership providers supported
[2016-12-29 19:47:42] <galvesribeiro> But I'm runnin on azure VMs with windows containers in it
[2016-12-29 19:47:56] <dragon788> agreed, but Zookeeper/Consul/etc will all solve this for your containers, so what is preventing you from using those or Azure Tables as your MemberShipPool?
[2016-12-29 19:48:01] <dragon788> or registry or whatever
[2016-12-29 19:48:20] <galvesribeiro> But even if I use zookeeper it will not fix my issue
[2016-12-29 19:48:28] <galvesribeiro> Neither consul or whatever registry
[2016-12-29 19:49:12] <dragon788> I think you are overthinking this
[2016-12-29 19:49:53] <dragon788> I'd just give it a try using Azure Tables or whatever, then if it does not work, you have exhausted the possibility, if you haven't tried it and are just assuming it won't work, then it is hard to suggest alternatives
[2016-12-29 19:50:09] <galvesribeiro> The problem is by the time my orleans silo  app is installing, it need to know which port it is using so it write it to membership table
[2016-12-29 19:50:18] <galvesribeiro> Or zookeeper or consul or whatever
[2016-12-29 19:50:34] <galvesribeiro> I already have orleans on several production apps
[2016-12-29 19:50:42] <galvesribeiro> Just jot in containers
[2016-12-29 19:51:12] <galvesribeiro> Installinng I meant starting (sorry on mobile now)
[2016-12-29 20:09:24] <galvesribeiro> Looks like registrator keeps pooling docker APIs to check the containers there and register them...
[2016-12-29 20:11:45] <galvesribeiro> I may have an idea :)
[2016-12-29 20:16:11] <galvesribeiro> From inside a container can I access the host ip machine (on docker virtual network) so I can make requests to dockerd REST api?
[2016-12-29 22:38:06] <galvesribeiro> dragon788: /@killerspaz?
[2016-12-29 22:39:54] <dragon788> yeah
[2016-12-29 22:40:21] <dragon788> the host may exist on the docker network depending on what options you run a container with
[2016-12-29 22:40:31] <dragon788> a lot of it is designed for isolation, but you can bypass that
[2016-12-29 22:41:41] <dragon788> or you could mount the docker socket into a specific container and present the REST api on the docker network, though security wise that is frowned upon
[2016-12-29 22:42:30] <galvesribeiro> Yeah I see an IP on the host that is on the container network and inside the container this very same IP is its gateway
[2016-12-29 22:42:52] <galvesribeiro> I cant use the socket hack because it is linux specific
[2016-12-29 22:42:58] <galvesribeiro> Windows doesnt have it
[2016-12-29 22:45:15] <dragon788> ahhh yeah, poor Windows :)
[2016-12-29 22:45:26] <galvesribeiro> Hehehe
[2016-12-29 22:45:28] <galvesribeiro> Yeah
[2016-12-29 22:45:44] <galvesribeiro> Anyway
[2016-12-29 22:46:05] <galvesribeiro> Will try this docker api workaround and see what I can found
[2016-12-29 22:46:35] <galvesribeiro> Maybe I can create a Orleans MEmbership provider who talks to docker api and query for the containers running orleans
[2016-12-29 22:46:41] <galvesribeiro> Will see 
[2016-12-30 10:34:22] <obernardovieira> I think, I have something important to say.It's the second time that this happens with me. I install docker on Linux Mint and after some hours the disk is full. Dont know why this happens, but I found out one thing, that also happens these two times. I lost all my system backups (I use timeshift). I dont know if it's some kind of conflit, but I think I have to report this, because it's a shame. The last time I had to reinstall my system, because I couldnt even start the system. This time, when I realise I had just 6GB left, I deleted some stuff here to have at least 20GB free, then disconnect from internet, restart, delete all docker images (Yes, I installed yesterday and I downloaded 4 images) then uninstall docker, and the magic happens. 100GB free right now ... Someone tells me. How this is even possibel that docker uses 100GB ? I was watching the free space decreasing. C'mon. Fix that. Until there, I will be using docker on a virtual machine, because I cant trust this software anymore.
[2016-12-30 12:03:14] <Forecaster> "Fix that."
[2016-12-30 12:03:18] <Forecaster> great feedback
[2016-12-30 13:13:34] <kkarolis> Hey, is it normal behaviour that memory footprint of processes running in docker container are not visible on the host? I.e. when I run 10 containers where each consumes 400MiB of space(reported by docker stats), host machines /proc/meminfo:MemoryAvailable stays mostly the same.
[2016-12-30 21:01:13] <dragon788> are they the same container? the kernel is pretty smart about shared vs isolated memory and if it is the same basic runspace it could be the majority of that is being reused between the containers unless you launched with some special cgroup magic to force isolation
[2016-12-30 21:02:10] <dragon788> obernardovieira: it sounds like you performed adocker pull somehugerepositoryinstead of adocker pull somehugerepository:specifictagand ended up filling your disk
[2016-12-30 21:02:58] <dragon788> josephgardner: Windows Server 2016 VM on Hyper-V or something else?
[2016-12-30 22:14:57] <obernardovieira> dragon788: doenst make any sense, because after I restart my computer, the disk free space keeps decreasing
[2016-12-30 22:16:56] <dragon788> if you look at the disk space being used, what directory is the most full? you can use the Disk Usage Analyzer tool if that is installed
[2017-01-01 21:34:08] <mmisztal1980> can docker-machine be scripted? I'd like to have a script to setup my env
[2017-01-01 21:34:16] <mmisztal1980> right now I'm having little luck with it
[2017-01-01 21:38:42] <SISheogorath> you can write a shell script which uses docker-machine
[2017-01-04 09:25:24] <siassaj> I also have 2 instructions, one updates my ruby gems, and one updates my node packages. No matter how i go about this, at some point one of those cache layers will be invalidated for no reason because the other changes
[2017-01-04 09:25:35] <siassaj> kylegordon_twitter: on 2 different machines too
[2017-01-04 09:29:04] <siassaj> the Dockerfile is a naively simple tool
[2017-01-04 09:29:35] <siassaj> would have been much more powerful if they had given us a ruby DSL to build out dockerfile descriptions, that way we could have implemented caching as we pleased
[2017-01-04 09:29:45] <siassaj> bbl
[2017-01-04 09:31:25] <kylegordon_twitter> hmm, wish I could help, but I'm equally as stuck
[2017-01-04 16:01:26] <Husamuddin> hello thereI have a problem to stop/kill containers on dockerit says: [<-CODE->] I'm on ubuntu 16.04here is my kernel version: 4.4.0-57-genericand docker version:Client: Version:      1.12.5 API version:  1.24 Go version:   go1.6.4 Git commit:   7392c3b Built:        Fri Dec 16 02:42:17 2016 OS/Arch:      linux/amd64Server:  Version:      1.12.5  API version:  1.24  Go version:   go1.6.4  Git commit:   7392c3b  Built:        Fri Dec 16 02:42:17 2016  OS/Arch:      linux/amd64and docker info:Containers: 1 Running: 1 Paused: 0 Stopped: 0 Images: 11 Server Version: 1.12.5 Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 16 Dirperm1 Supported: true Logging Driver: json-file Cgroup Driver: cgroupfsPlugins:Volume: local Network: bridge null overlay host Swarm: inactive Runtimes: runc Default Runtime: runc Security Options: apparmor seccomp Kernel Version: 4.4.0-57-generic Operating System: Ubuntu 16.04.1 LTS OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 7.683 GiB Name: husamuddin-Aspire-E1-572G ID: RLPM:FCJP:LJQV:5OZZ:P7QS:NA4M:QET7:LTMX:NWTZ:EUOI:NLOR:FZPK Docker Root Dir: /var/lib/docker Debug Mode (client): false Debug Mode (server): false Username: husamuddin Registry: https://index.docker.io/v1/ WARNING: No swap limit support Insecure Registries:  127.0.0.0/8
[2017-01-04 16:03:27] <Husamuddin> any ideas!
[2017-01-04 16:14:42] <matrixbot> @quaddo:matrix.orgdid you originally start the container from root, and are now trying to stop it as a regular user?
[2017-01-04 17:00:21] <dragon788> siassaj: you simply combine your two commands into one "call" and this would create a single layer with all the changes from both, IIRC you can also while building a container run a couple commands from the command line and then "commit" afterwards in order to control when the layer actually gets saved
[2017-01-04 18:32:02] <mmisztal1980> matrixbot: I've managed to resolve the network issues we've been investigating 2 days ago. the boot2docker vm now has NW connectivity and is getting an ip v4 address, however the docker service is listening on:::2376and is thus unreachable from the outside ... what the heck?
[2017-01-04 18:33:17] <matrixbot> @quaddo:matrix.orgthat's an ipv6 socket
[2017-01-04 18:33:33] <matrixbot> @quaddo:matrix.orgwould need to get it so that it listens on ipv4
[2017-01-04 18:36:13] <matrixbot> @quaddo:matrix.orgactually, that may not even be an issue, as it should be implicit
[2017-01-04 18:37:21] <matrixbot> @quaddo:matrix.orgassumingtelnetis installed on the VM, can you connect usingtelnet localhost 2376?
[2017-01-04 18:40:17] <mmisztal1980> let me check that
[2017-01-04 18:40:41] <mmisztal1980> let me check that
[2017-01-04 18:41:43] <mmisztal1980> connection was successful
[2017-01-04 18:45:18] <matjazmav> Hey anyone using microsoft/mssql-server-Linux image?
[2017-01-04 18:46:07] <matrixbot> @quaddo:matrix.orgbut no joy connecting to that socket from outside the VM?
[2017-01-04 18:48:28] <mmisztal1980> yep
[2017-01-04 18:48:44] <mmisztal1980> curiously I can ping it though
[2017-01-04 18:48:51] <mmisztal1980> PS D:\\Checkout\\PoC.Docker> test-netconnection 192.168.8.101 -port 2376WARNING: TCP connect to 192.168.8.101:2376 failedComputerName           : 192.168.8.101RemoteAddress          : 192.168.8.101RemotePort             : 2376InterfaceAlias         : vEthernet (DockerExternal)SourceAddress          : 192.168.8.101PingSucceeded          : TruePingReplyDetails (RTT) : 0 msTcpTestSucceeded       : False
[2017-01-04 18:49:17] <mmisztal1980> I can connect from the inside, but not from the outside
[2017-01-04 18:49:17] <mmisztal1980> boot2docker doesn't have a firewall - does it?
[2017-01-04 18:49:39] <matrixbot> @quaddo:matrix.orgit shouldn't, that would aggravate a lot of folks out of the gate :)
[2017-01-04 18:49:43] <mmisztal1980> boot2docker doesn't have a firewall - does it?
[2017-01-04 18:50:08] <matrixbot> @quaddo:matrix.orgbut is there a Windows firewall at play, here?
[2017-01-04 18:50:09] <dragon788> it shouldn't have a firewall, but you are essentially going through 2 layers of networking
[2017-01-04 18:51:36] <dragon788> ovidiub13: typically I\'ve seen places maintain two images, one for building and one for running, they could both inherit from the same base image and your build script could build the "build" and then use that to create the "run"
[2017-01-04 18:52:27] <mmisztal1980> I don't believe so, but I'll double check
[2017-01-04 18:53:07] <madpipeline> dragon788: that is the plan, but I'm not sure if we can do the inheritance thing, sice the devel image will be very much different
[2017-01-04 18:53:11] <mmisztal1980> no change after disabling the windows firewall
[2017-01-04 18:54:02] <dragon788> oh yeah, you would have  base => devel and base => runtime, you wouldn't want to go base => devel => runtime, that would bloat the image too much
[2017-01-04 19:06:58] <dragon788> so the runtime image uses a package that you are compiling in the devel image or it requires an environment similar to the devel image minus a few devel packages?
[2017-01-04 21:22:52] <matrixbot> @quaddo:matrix.orgfrom what I'm seeing, the container id is always a uniquely generated hexadecimal number
[2017-01-04 23:24:24] <dragon788> the container ID is a random GUID, you can pass the--name somenameto adocker runcommand to give it a name you can reference, but it needs to be unique
[2017-01-04 20:50:33] <galvesribeiro> guys, the container id by default is always be set as hostname, right?
[2017-01-04 21:22:52] <matrixbot> @quaddo:matrix.orgfrom what I'm seeing, the container id is always a uniquely generated hexadecimal number
[2017-01-04 23:24:24] <dragon788> the container ID is a random GUID, you can pass the--name somenameto adocker runcommand to give it a name you can reference, but it needs to be unique
[2017-01-04 23:24:41] <dragon788> galvesribeiro: ^^
[2017-01-04 23:25:16] <galvesribeiro> hey
[2017-01-04 23:25:20] <galvesribeiro> hum...
[2017-01-04 23:25:29] <galvesribeiro> the point is not the container name actually
[2017-01-04 23:25:40] <galvesribeiro> I'm trying to get the hostname itself
[2017-01-05 00:11:49] <matrixbot> @quaddo:matrix.orgwait, you said you can rundocker exec -iton the container, and you can indeed see the files you want?
[2017-01-05 11:30:42] <ioan-cristea> Hi. I want to know if I can run multiple websites on a server, served by multiple containers.
[2017-01-05 11:31:47] <Bajix> KRIOFT: Yes; use something like ELB to do the port mappings then run containers on separate ports
[2017-01-05 11:32:41] <ioan-cristea> I understand, I will try. Thanks!
[2017-01-05 13:43:15] <galvesribeiro> hey guys, how can my container access the host machine? I mean, which of the IPs the containers should hit to get to the host?
[2017-01-05 14:05:10] <SISheogorath> galvesribeiro: Use the hostname of your machine. That's the easiest way
[2017-01-05 14:31:49] <am0nshi> galvesribeiro: for what purposes you nedd host machine?
[2017-01-05 14:32:27] <galvesribeiro> the container need to query the Docker Remote API of the host to check some stuff
[2017-01-05 14:32:54] <am0nshi> galvesribeiro: you can mount host docker.sock into your machine
[2017-01-05 14:33:03] <am0nshi> and write http requests into it
[2017-01-05 14:33:10] <galvesribeiro> there is no docker.sock in windows :(
[2017-01-05 14:46:34] <am0nshi> use unix 8)
[2017-01-05 14:57:02] <galvesribeiro> I cant hehehe
[2017-01-05 15:14:31] <damilare> Question, anyone has a strategy to make Docker Builds faster, I don’t have to re-install my libraries and dependencies all the time I make tiny changes to my source code
[2017-01-05 15:15:03] <am0nshi> damilare: MOUNT?
[2017-01-05 15:15:37] <am0nshi> and then will be no need to use builds at all, build is environment only for dev
[2017-01-05 15:23:37] <damilare> MOUNT?
[2017-01-05 15:23:58] <damilare> how do you mean, and dev env is actaullly my main concerned
[2017-01-05 15:24:44] <am0nshi> damilare: $ docker run -d -P \\--volume-driver=flocker \\-v my-named-volume:/webapp \\ <- this line--name web training/webapp python app.py
[2017-01-05 15:24:50] <am0nshi>  [<-LINK->] 
[2017-01-05 15:26:01] <damilare> hmmm
[2017-01-05 15:26:02] <damilare> thanks
[2017-01-05 15:27:31] <galvesribeiro> there must be a way to a container to talk to a docker host :(
[2017-01-05 15:27:45] <damilare> this way, I dont have to build images when I make changes to my source code then
[2017-01-05 15:27:48] <damilare> makes sense thanks
[2017-01-05 15:28:26] <am0nshi> galvesribeiro:  [<-LINK->] and dont use windows ^^
[2017-01-05 15:28:35] <am0nshi> damilare: +
[2017-01-05 15:28:53] <galvesribeiro> am0nshi: that is what I'm using
[2017-01-05 15:29:08] <galvesribeiro> don't use windows is not an option
[2017-01-05 15:29:58] <am0nshi> galvesribeiro: its called lxc containers (linux containers), in windows you loose all features they provide :) and u make from docker vagrant :)
[2017-01-05 15:30:21] <galvesribeiro> not anymore
[2017-01-05 15:30:31] <galvesribeiro> its is not lxc cotnainers-only anymore
[2017-01-05 16:29:24] <SISheogorath> @damilare Check some onbuild images. Like https://github.com/nodejs/docker-node/blob/master/7.4/onbuild/DockerfileThey are made to preinstall dependencies.
[2017-01-05 16:32:50] <damilare> thanks@SISheogorath
[2017-01-06 16:24:16] <iDVB> Anyone know of a good example code/repo for Docker(dev+prod)+Node App(requiring build) ?
[2017-01-06 16:25:26] <killerspaz> Unfortunately I had not seen a complete/good sample, and I'm not capable of open-sourcing mine atm, but if you need help feel free to ask... I will say this, check outdocker-composethe second you understand how to make a Dockerfile, and deep dive into networking and volumes, and you should get up to speed pretty quick
[2017-01-06 16:26:17] <killerspaz> at least nothing that suited my needs and/or standards.... I took a TDD approach for development locally, and integration tests for containerized development
[2017-01-06 16:51:19] <sc6l6d3v> Hi, am trying to debug a container that blows up starting my app and am down to looking at linux startup files that process various config files. Why would I be getting a permission denied when trying to copy the entire image from the root as follows:montreux:mlt-viz hkatz$ docker cp   d340eba864a1:/ ~/tmp/dockroot\nmkdir /Users/hkatz/tmp/dockroot/consul-template/config.d: permission denied?
[2017-01-06 16:40:14] <iDVB> how do I get the output of that command into a production enviroment.... and if my DEV compose uses a container for DB.... then what  should PROD use. (considering alot of people seem to think docker+db+prod === bad)
[2017-01-06 16:40:49] <killerspaz> iDVB: i PM'd you
[2017-01-06 16:42:32] <andersonkyle> Is there anyway to force docker to store credentials in plaintext in the config file?  It is keeps using wincred and I don't want to use that...
[2017-01-06 16:43:10] <andersonkyle> I've logged out and logged back in to no avail.
[2017-01-06 16:43:42] <andersonkyle> I definitely remember my local machine storing them in the config file, but for some reason it now is only using wincred.   Any ideas?
[2017-01-06 16:45:40] <killerspaz> creds for a registry?
[2017-01-06 16:45:56] <killerspaz>  [<-LINK->] 
[2017-01-06 16:48:25] <andersonkyle> Yes
[2017-01-06 16:49:35] <andersonkyle> How can I force docker to use the config file to store the credentials instead of wincred on Windows?
[2017-01-06 16:51:19] <sc6l6d3v> Hi, am trying to debug a container that blows up starting my app and am down to looking at linux startup files that process various config files. Why would I be getting a permission denied when trying to copy the entire image from the root as follows:montreux:mlt-viz hkatz$ docker cp   d340eba864a1:/ ~/tmp/dockroot\nmkdir /Users/hkatz/tmp/dockroot/consul-template/config.d: permission denied?
[2017-01-06 16:51:47] <killerspaz> it says on that page how to define the credStore, please read the page I sent.
[2017-01-06 16:52:15] <andersonkyle> killerspaz: No it doesn't.
[2017-01-06 16:52:52] <killerspaz> so you don\'t see the 42pt font text that says "Credentials store" ???
[2017-01-06 16:53:03] <killerspaz> and the subheader entitled "Usage" ?
[2017-01-06 16:53:36] <andersonkyle> killerspaz: I guess you didn't read it cause it doesn't explain how to set the config to use plain text.
[2017-01-06 16:53:42] <andersonkyle> killerspaz: It only gives a single example of setting it to Mac OSX's credential manager.
[2017-01-06 16:54:32] <andersonkyle> killerspaz: If you see it there, what exactly is the setting for plain text?
[2017-01-06 16:55:18] <killerspaz> dude, if you can't read, that's on you... there's literally 3 bullet points in that section indicating your options
[2017-01-06 16:55:35] <killerspaz> This is the list of currently available credentials helpers and where you can download them from:
[2017-01-06 16:55:52] <andersonkyle> D-BUS, MacOS, Windows...
[2017-01-06 16:56:02] <killerspaz> READ THE WHOLE PAGE, I'm done talking to people that don't RTFM
[2017-01-06 16:56:22] <andersonkyle> killerspaz: Again, if it were there, you'd answer the question.  It aint', so you can't.
[2017-01-06 16:57:16] <killerspaz> dude, you either choose one of the 3, or use a config, just like it says on the page
[2017-01-06 16:57:26] <killerspaz> the end, done.... there's no more conversation happening between us at this point.
[2017-01-06 16:58:01] <SISheogorath> iDVB: may check hackmd, we build an awesome docker container there
[2017-01-06 18:02:15] <galvesribeiro> hey guys
[2017-01-06 18:02:19] <galvesribeiro> quick question...
[2017-01-06 18:02:40] <galvesribeiro> is there a way to docker monitor if a service inside the container is alive or not?
[2017-01-06 18:02:40] <galvesribeiro> is there a way to docker monitor if a service inside the container is alive or not?
[2017-01-06 18:03:59] <galvesribeiro> I mean, the main ENTRYPOINT is alive, so from docker perspective, the container is running however, some internal crap happen on the app and I need docker to check with some sort of heartbeat the application (idk, a ping on a specific port or whatever) and if it does'nt reply, just kill the container... is it possible?
[2017-01-06 18:03:59] <galvesribeiro> I mean, the main ENTRYPOINT is alive, so from docker perspective, the container is running however, some internal crap happen on the app and I need docker to check with some sort of heartbeat the application (idk, a ping on a specific port or whatever) and if it does'nt reply, just kill the container... is it possible?
[2017-01-06 18:05:55] <killerspaz> need some health monitoring internal and external to the container; something internal to keep checking the status of what you need running/accessible, and something external to poll it once in a while to know to kill/restart it.... there's unfortunately so many ways to accomplish this, it just depends on what level of effort you want to put into it.
[2017-01-06 18:05:55] <killerspaz> need some health monitoring internal and external to the container; something internal to keep checking the status of what you need running/accessible, and something external to poll it once in a while to know to kill/restart it.... there's unfortunately so many ways to accomplish this, it just depends on what level of effort you want to put into it.
[2017-01-06 18:06:33] <killerspaz> you could simplyexecaps | grep APPto see if it's running external from container on the host
[2017-01-06 18:06:33] <killerspaz> you could simplyexecaps | grep APPto see if it's running external from container on the host
[2017-01-06 18:06:34] <galvesribeiro> killerspaz: hey! :)
[2017-01-06 18:06:50] <galvesribeiro> that is the poin
[2017-01-06 18:06:52] <galvesribeiro> point
[2017-01-06 18:07:47] <galvesribeiro> in Orleans we have a health monitoring service which all nodes of the cluster ping each other and after a given number of ping fail from some servers, they declare it dead, and remove from the cluster membership ring
[2017-01-06 18:08:08] <galvesribeiro> it already works pretty fine on VMs and bare metal
[2017-01-06 18:08:24] <galvesribeiro> I did implemented an Docker membership provider
[2017-01-06 18:08:57] <galvesribeiro> the problem now is that for the provider, it only knows if a node is up or down only by checking docker daemon if it is up or down
[2017-01-06 18:08:59] <galvesribeiro> and that is our problem
[2017-01-06 18:09:18] <galvesribeiro> a container can be app, but some internal thread in the application process for whatever reason is blocked
[2017-01-06 18:09:31] <galvesribeiro> so no new requests should go to that node
[2017-01-06 18:09:45] <galvesribeiro> so the idea is to ask docker (or swarm) to kill that node
[2017-01-06 18:10:01] <galvesribeiro> but to be sure of that, I need to detect this stallness correctly
[2017-01-06 18:10:19] <killerspaz> how is the provider checking daemon status?
[2017-01-06 18:10:31] <killerspaz> remember, i know nothing about Orleans, so my apologies for simpleton questions related to that
[2017-01-06 18:11:54] <galvesribeiro> nah no worries :D
[2017-01-06 18:12:40] <galvesribeiro> that is another problem :D
[2017-01-06 18:12:55] <killerspaz> if you are simply doing adocker ps | grep MY_CONTAINER_NAME | grep Runningor something of the nature, it's simple to also do something like:docker exec MY_CONTAINER_NAME ps aux | grep processordocker exec MY_CONTAINER_NAME ping somehost.com
[2017-01-06 18:13:35] <galvesribeiro> in linux, you map docker.socket and you make docker API requests to it
[2017-01-06 18:13:51] <galvesribeiro> but on windows, there is no docker.socket!!! o.o
[2017-01-06 18:16:30] <killerspaz> imo it's best to keep that check external to the container... i like to couple things downstream instead of upstream... but that's preference
[2017-01-06 18:16:45] <galvesribeiro> we have this check external
[2017-01-06 18:17:10] <galvesribeiro> each node of Orleans cluster (which is a container) send health messages to each other
[2017-01-06 18:17:40] <galvesribeiro> the rendevour point of those messages, used to be the membership table
[2017-01-06 18:17:59] <galvesribeiro> if multiple nodes try to reach a node and fail (lets say 3 times), that node is marked as dead
[2017-01-06 18:18:03] <galvesribeiro> even if the machine is running
[2017-01-06 18:18:09] <galvesribeiro> so noone will send a message to it again
[2017-01-06 18:18:16] <galvesribeiro> now, in docker, we don't have that table
[2017-01-06 18:18:25] <galvesribeiro> we were relying on docker labels
[2017-01-06 18:19:09] <galvesribeiro> so each Orleans node should query docker (or swarm) daemon periodically about all the containers with a given Label that are running
[2017-01-06 18:19:22] <galvesribeiro> that would make them know who is on the cluster
[2017-01-06 18:20:31] <galvesribeiro> if a container is killed/exit, next query on docker api will return all containers - that one
[2017-01-06 18:20:56] <galvesribeiro> that is ok for periodic refreshes and consider only the container up or down
[2017-01-06 18:21:01] <galvesribeiro> the problem is internal
[2017-01-06 18:21:15] <galvesribeiro> I need to mark a container as dead even if it is running
[2017-01-06 18:21:18] <killerspaz> could you then iterate over all the containers and exec a "health check" script that is consistently implemented?
[2017-01-06 18:21:32] <killerspaz> even if it does NOTHING?
[2017-01-06 18:22:00] <galvesribeiro> the problem is not the healthcheck mecanism
[2017-01-06 18:22:03] <galvesribeiro> we already have it
[2017-01-06 18:22:09] <galvesribeiro> the problem is how to mark it as dead
[2017-01-06 18:22:30] <killerspaz> errr, other than just killing the container?
[2017-01-06 18:22:40] <killerspaz> or can you modify a label?
[2017-01-06 18:22:50] <galvesribeiro> ok way, let me rephrase
[2017-01-06 18:22:53] <killerspaz> i haven't messed with labels really outside of RancherOs
[2017-01-06 18:23:12] <galvesribeiro> the problem is how to save the counted votes to kill that node
[2017-01-06 18:23:17] <killerspaz> so my knowledge there is low as well, other than you can kinda query against them
[2017-01-06 18:23:31] <galvesribeiro> remember, before docker, we had that table as a central point
[2017-01-06 18:23:35] <galvesribeiro> now I have labels
[2017-01-06 18:23:38] <galvesribeiro> so the ideal would be
[2017-01-06 21:33:01] <galvesribeiro> There are 2 types of health check. Local, where if unhealthy, just suicide(the HEALTHCHECK is a good candidate for that) and the distributed consensus, which is made by external sources trying to reach that container and failing, so they agree on ask docker to kill it
[2017-01-06 21:33:46] <galvesribeiro> In orleans case the consensus is what I'm having problems to implement in docker due to those limitations
[2017-01-06 21:34:20] <galvesribeiro> The self check can be made with the HEALTHCHECK just fine I guess
[2017-01-06 21:37:18] <iDVB> Docker, Docker Compose, Docker Swarms, Docker Cloud..... docker-compose.yml, docker-cloud.yml, services.yml(Cloud66), build.yml(Cloud66), codeship-services.yml(Codeship), codeship-steps.yml(Codeship)    does anyone else's brain hurt.... or just me?
[2017-01-06 21:38:01] <iDVB> I've pretty well got dev docker workflow working. I'm starting to loose hope for that to translate into a prod docker stack
[2017-01-06 21:39:19] <iDVB> docker-compose.ymlseems like a great implementation/standard file.... why did we feel the need to createdocker-cloud.yml?
[2017-01-06 21:39:20] <galvesribeiro> iDVB: this is called "Docker ecosystem around Docker"
[2017-01-06 21:39:36] <galvesribeiro> Anyway
[2017-01-06 21:38:01] <iDVB> I've pretty well got dev docker workflow working. I'm starting to loose hope for that to translate into a prod docker stack
[2017-01-06 21:39:19] <iDVB> docker-compose.ymlseems like a great implementation/standard file.... why did we feel the need to createdocker-cloud.yml?
[2017-01-06 21:39:20] <galvesribeiro> iDVB: this is called "Docker ecosystem around Docker"
[2017-01-06 21:39:36] <galvesribeiro> Anyway
[2017-01-06 21:40:37] <galvesribeiro> killerspaz: @SISheogorathbut nothing of those health check strategies will work if I'm unable to reach docker daemon api from inside the container 
[2017-01-06 21:41:08] <killerspaz> kill your main process to kill the container?
[2017-01-06 21:41:22] <killerspaz> otherwise, you need an orchestration system like kubernetes or rancher
[2017-01-06 21:42:23] <SISheogorath> galvesribeiro: Why should you need to reach the docker api from inside the container? As mentioned for unreachable nodes you have orchestration solutions like K8s, Rancher or swarm. They take care about that
[2017-01-06 21:42:33] <iDVB> galvesribeiro: Sorry, just burning out trying to ramp up to all things Docker/Containerizing. Still have a ton to learn about related best practises etc. Not wanting to deal with the Ops side of things. Docker Cloud seems to promise as much.... but requires another filedocker-cloud.ymlcreated, so I'm curious why. docker-compose seems to contain much of the same.
[2017-01-06 21:43:04] <iDVB> The same can be said about many other docker hosts or CI tools. Eg. my examples of codeship and cloud66
[2017-01-06 21:43:52] <SISheogorath> iDVB: it\'s really annoying yes :D but everyone have their own "best way to do it" so mhm have to deal with it
[2017-01-06 21:47:43] <galvesribeiro> @killerspazkill your main process to kill the container?That is doable for the local check@SISheogorathThe app running in the container have to read some labels from docker API to know which containers are part of the cluster and then inspect each one to get their IPs to connect to.We don't want to enforce users to use an external orchestration solution because none of them, will get what we need. In fact, we are using Swarm... When I say query Docker API, I mean query it thru Swarm endpoint
[2017-01-06 21:47:53] <iDVB> SISheogorath: thanks. I'm starting to see that now. I guess I'm a perfectionist and struggling with needing to guess at the best foot forward.  Wish someone would feel opinionated enough to just point to a workflow that seems to work well for them.  Docker Cloud looks decent but it is prod ready? Cloud66 looks like ikea for docker (in a good easy way) but I'mn struggling with their build process.
[2017-01-07 05:15:29] <killerspaz> galvesribeiro: i hope you're gonna blog this stuff :P
[2017-01-07 05:15:56] <galvesribeiro> blog what? my failure getting docker to work with Orleans? :P
[2017-01-07 05:16:14] <killerspaz> lol and your eventual success, of course!
[2017-01-07 05:17:17] <galvesribeiro> I hope so :D
[2017-01-07 07:29:16] <SISheogorath> I don't know all those microsoft languages tends to have ultra long names for their methods and objects
[2017-01-07 07:29:26] <galvesribeiro> hehehehehe
[2017-01-07 07:30:17] <SISheogorath> same applies to commandline programs :(dirvsls
[2017-01-07 07:33:14] <SISheogorath> I have native C++ or NodeJS for that :D
[2017-01-07 07:33:30] <SISheogorath> sometimes in combination \\o/
[2017-01-07 07:33:51] <galvesribeiro>  [<-CODE->] 
[2017-01-07 07:34:23] <galvesribeiro> that simple code in Orleans means that each of those actor tasks will run in a diff silo (a node/server in the cluster) and you get the result back
[2017-01-07 07:34:35] <galvesribeiro> it is wonderful :D
[2017-01-07 07:35:03] <galvesribeiro> my next fun project will be write Orleans fully in TypeScript for node.js :D
[2017-01-07 07:36:22] <galvesribeiro> let give node community some real distributed framework :D
[2017-01-07 07:38:58] <killerspaz> <3 TS. Ready for ES9 by now.... let's get to a real language! :P
[2017-01-07 07:40:32] <SISheogorath> oh yes! but we have to mention that in general nodejs already includes a cluster framework :D so not sure how useful it is :D But I'll give it a try
[2017-01-07 07:42:24] <killerspaz> true, it's pretty useful, too
[2017-01-07 07:43:50] <galvesribeiro> cluster in node is not a real cluster
[2017-01-07 07:44:12] <galvesribeiro> it is just a proxy/main process which spawn other process and forward requests to be processed there
[2017-01-07 07:44:26] <galvesribeiro> node (because of V8 and libUV) has a single thread
[2017-01-07 07:44:37] <galvesribeiro> so each node.exe process is 1 single thread
[2017-01-07 07:45:11] <galvesribeiro> what cluster does is multiplex that thread with diff process at cost of serialization and marshaling between process
[2017-01-07 07:45:36] <galvesribeiro> so you basically have 1+CPUThreadCount node processes per machine
[2017-01-07 07:45:39] <galvesribeiro> this is their cluster
[2017-01-07 08:00:00] <galvesribeiro> and my docker swarm init still running :(
[2017-01-07 08:03:01] <galvesribeiro> ok... its almost 6am here and I'm fighting this thing
[2017-01-07 08:03:04] <galvesribeiro> time to sleep
[2017-01-07 08:03:17] <galvesribeiro> night all bb tomorrow and thanks for all help again
[2017-01-07 08:03:32] <SISheogorath> galvesribeiro: yes, that's how nodes cluster works :D and you can build a abstraction over it to add remote nodes too :D it was very easy and very useful as we simply passed API requests trough it and ended up in nicely scaling setup
[2017-01-07 08:03:38] <SISheogorath> See you
[2017-01-07 08:03:54] <galvesribeiro> yeah
[2017-01-07 08:04:08] <galvesribeiro> but that is just usefull for stateless request/response kind of app
[2017-01-07 08:04:21] <galvesribeiro> like web servers and maybe websocket server
[2017-01-07 08:04:27] <galvesribeiro> but you can't do much with that
[2017-01-07 08:04:56] <galvesribeiro> when I find time will start the project and let you know
[2017-01-07 08:05:10] <galvesribeiro> anyway, ttyl night
[2017-01-07 08:05:49] <SISheogorath>  I'm waiting for it ;)
[2017-01-07 08:44:28] <nischay30> how to define links in docker-compose file if i want to deploy on the warm
[2017-01-07 08:44:30] <nischay30> swarm
[2017-01-07 08:45:20] <SISheogorath> you should not use links in this case. Address the services and may add network aliases
[2017-01-07 08:46:08] <nischay30> means how??i m not getting you..like i m having 3 service ..one is redis ,another one is neo4j and third one my nodejs app which has to run on 8081
[2017-01-07 08:48:52] <nischay30> ?
[2017-01-07 08:56:15] <SISheogorath> oh wait you talk about compose v3?
[2017-01-07 08:56:31] <nischay30> yes i m talking about that
[2017-01-07 08:57:07] <nischay30> i dont know how to write compose version 3.but i have to user version  3 so that i cn deploy a stack in docker 1.13 using compose nt bundle
[2017-01-07 08:57:23] <SISheogorath>  [<-LINK->] 
[2017-01-07 08:57:42] <SISheogorath> should be a nice example
[2017-01-07 08:58:06] <nischay30> ok i will explore...thanx
[2017-01-07 09:12:46] <nischay30> SISheogorath: but tell me i m having one environment vairable in nodejs app i.e.neo4j Url and i have to mention it in that and i have to refer that neo4j.so without links how i mention that?
[2017-01-07 09:14:36] <SISheogorath> set the url to the servicename of your neo4j service. if you name it "foo" use " [<-LINK->] " as url. docker swarm networking will do the rest
[2017-01-07 09:17:18] <nischay30> is it necessary that  i have to define the network also?
[2017-01-07 12:59:05] <SISheogorath> yes
[2017-01-07 15:39:00] <galvesribeiro> Afternoon! 
[2017-01-07 15:39:00] <galvesribeiro> Afternoon! 
[2017-01-07 17:09:04] <galvesribeiro> SISheogorath: the swarm init never worked :(
[2017-01-07 17:09:04] <galvesribeiro> SISheogorath: the swarm init never worked :(
[2017-01-07 17:10:31] <SISheogorath>  I have no real idea why this happens. Are you know part of the docker community?
[2017-01-07 17:10:31] <SISheogorath>  I have no real idea why this happens. Are you know part of the docker community?
[2017-01-07 17:11:36] <galvesribeiro> nop... got one email from Victor Coisne saying in other words, wait :(
[2017-01-07 17:11:36] <galvesribeiro> nop... got one email from Victor Coisne saying in other words, wait :(
[2017-01-07 17:17:56] <SISheogorath> Oh okay :o that's new
[2017-01-07 17:17:56] <SISheogorath> Oh okay :o that's new
[2017-01-07 17:20:28] <galvesribeiro> the chat is probably too bloated
[2017-01-07 17:20:28] <galvesribeiro> the chat is probably too bloated
[2017-01-07 17:20:41] <galvesribeiro> so they are controlling access now unfortunately :(
[2017-01-07 17:20:41] <galvesribeiro> so they are controlling access now unfortunately :(
[2017-01-07 17:33:29] <galvesribeiro> frustrating
[2017-01-07 17:33:29] <galvesribeiro> frustrating
[2017-01-07 17:39:31] <SISheogorath> I aggree with that but I currently have no idea. Maybe you can file an issue on github
[2017-01-07 17:39:31] <SISheogorath> I aggree with that but I currently have no idea. Maybe you can file an issue on github
[2017-01-07 17:40:31] <galvesribeiro> nah, don't want be an 4ss... let them take their time...
[2017-01-07 17:40:31] <galvesribeiro> nah, don't want be an 4ss... let them take their time...
[2017-01-07 17:41:08] <galvesribeiro> regardless of swarm, I still have the Orleans <-> Docker stuff to deal with
[2017-01-07 17:41:08] <galvesribeiro> regardless of swarm, I still have the Orleans <-> Docker stuff to deal with
[2017-01-07 17:42:39] <galvesribeiro> I read thru whole swarm docs yesterday (or Today? Who knows!) before sleep... it is very simple and has not much for my case actually
[2017-01-07 17:42:39] <galvesribeiro> I read thru whole swarm docs yesterday (or Today? Who knows!) before sleep... it is very simple and has not much for my case actually
[2017-01-07 17:44:10] <galvesribeiro> the Orleans cluster deployment is not actually related to swarm... the only feature of swarm that is actually used but totally unrelated, is the placement strategy of containers on hosts and the desired state... thats it... load balancing etc, those things we will never use
[2017-01-07 17:44:10] <galvesribeiro> the Orleans cluster deployment is not actually related to swarm... the only feature of swarm that is actually used but totally unrelated, is the placement strategy of containers on hosts and the desired state... thats it... load balancing etc, those things we will never use
[2017-01-07 17:45:07] <galvesribeiro> so a single standalone docker host or a swarm cluster makes no diff for me... what we care are the labels and find a way to proper health check the service
[2017-01-07 17:45:07] <galvesribeiro> so a single standalone docker host or a swarm cluster makes no diff for me... what we care are the labels and find a way to proper health check the service
[2017-01-07 20:22:19] <vyscond> Hey guys! is it possible to point to anotherdocker-compose.ymlfile  withdocker-composecommand just like we withdocker build?
[2017-01-07 20:25:24] <galvesribeiro> vyscond: use-fjust as indocker build
[2017-01-07 20:25:43] <galvesribeiro> docker-compose up -f somefile.yml
[2017-01-07 20:25:57] <vyscond> galvesribeiro: thanks a million sport!
[2017-01-07 20:26:56] <galvesribeiro> vyscond: most of docker commands just havedocker [command] --helpso the majority of parameters are there
[2017-01-07 20:27:51] <vyscond> galvesribeiro: yup. but i forgot to run that underdocker-composealone. Instead i wasdocker-compose up --help. :/
[2017-01-07 20:28:58] <galvesribeiro> you are right
[2017-01-08 13:14:26] <jjohnson1994> Hello, I want to be able to clone a repo into my docker container at run time. Because I'm using SSH to get read-only access to my repo I need to have the keys within the docker container somewhere. Is it safe to keep the public and private keys within the containers files and then link the volume in the docker-compose file? or should I be doing this another way?
[2017-01-08 13:54:29] <SISheogorath> jjohnson1994: it depends on your "secretness". If it\'s a deployment key and it\'s not a problem if everyone has it. Include it. If it is a problem, you can thing aboutmount the key to container\nadd it as environment variables\nwait vor 1.13 and add it as secret
[2017-01-08 13:57:56] <jjohnson1994> SISheogorath: It's just a deployment key so should be okay, thanks
[2017-01-08 13:58:44] <SISheogorath> You can think about it like about "would I include that into  my github repository" ;)
[2017-01-08 13:14:26] <jjohnson1994> Hello, I want to be able to clone a repo into my docker container at run time. Because I'm using SSH to get read-only access to my repo I need to have the keys within the docker container somewhere. Is it safe to keep the public and private keys within the containers files and then link the volume in the docker-compose file? or should I be doing this another way?
[2017-01-08 13:54:29] <SISheogorath> jjohnson1994: it depends on your "secretness". If it\'s a deployment key and it\'s not a problem if everyone has it. Include it. If it is a problem, you can thing aboutmount the key to container\nadd it as environment variables\nwait vor 1.13 and add it as secret
[2017-01-08 13:57:56] <jjohnson1994> SISheogorath: It's just a deployment key so should be okay, thanks
[2017-01-08 13:58:44] <SISheogorath> You can think about it like about "would I include that into  my github repository" ;)
[2017-01-09 08:48:26] <matrixbot> Baffyis anyone having trouble starting docker on the latest Mint?
[2017-01-09 08:48:30] <matrixbot> Baffyi think it's a systemd issue
[2017-01-09 21:24:17] <killerspaz> anyway, i find it funny that Education somehow has more support than Home :P
[2017-01-09 21:24:19] <somombo> anyhow@killerspazi'm not here to debate toolbox, this is not the right place for this.. Just thought I'd shout out to anybody that's helping maintain the toolbox repo to give the Issue and PR a serious and honest look. I am not the only one who thinks there is something wrong docker-toolbox workflow. So if the outcome of giving it an honest look and discussing how to move forward is a decision that that PR is not the best way to do it and a better way is provided.. then that's great! I'm all for that. We invite you to engage on github.
[2017-01-09 22:51:32] <NickStefan> docker-compose down && docker-compose build && docker-compose up, i used to be able to pair these and it would only rebuild images when things needed to be. my containers are now being rebuilt from scratch every time. any reason one could think?
[2017-01-09 22:53:35] <NickStefan>  [<-CODE->] used to be, that if i hadnt changed requirements.txt, it would reuse that cache. i have not changed requirements.txt and for some reason its bailing and not using the cache
[2017-01-09 22:54:28] <killerspaz> is your source is changing between builds? or are you clearing any dangling containers at any point?
[2017-01-09 22:55:47] <NickStefan> its rebuilding containers that i have definitely not changed. for example, im changing stuff in a django container, but theres a node container i never touch, and its going through all the npm install bs that usually only happens when the package.json is different (invalidates the build)
[2017-01-09 22:56:21] <killerspaz> looks like cache is actually breaking at step 3; which is very strange
[2017-01-09 22:56:36] <killerspaz> is something else changing the contents of/usr/srcfrom a shared volume?
[2017-01-09 23:18:58] <NickStefan> even justdocker build .in the directory repeatedly builds the entire thing. i have nothing else running. not changing any code. any ideas where to look?
[2017-01-09 23:22:46] <NickStefan> how can I debug that WORKDIR /usr/src keeps making a different checksum?
[2017-01-10 00:00:05] <NickStefan> so another dev, same code, not having this problem... so my computer i guess
[2017-01-10 00:23:35] <NickStefan> SOMEONE_IMPORTANT: (lol), the problem was that i was on 1.13.0-rc beta. Rolling back to 1.12.5 stable fixed everything!
[2017-01-10 21:48:59] <holmser> I've got an interesting issue... I'm running docker containers and the application is reporting significant time skew
[2017-01-10 21:49:32] <holmser> but when I check on both the host and the container using date and hwclock they are both identical and correct
[2017-01-11 04:12:39] <quickeee> Hi , is there any documentation or checklist before moving application into production running in docker?
[2017-01-11 07:06:39] <kschlesselmann> quickeee: Well there are recommendations for production docker daemon setups … regarding to your application: propably the same you had before.
